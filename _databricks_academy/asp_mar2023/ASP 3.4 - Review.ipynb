{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"654ae960-3ba6-4f70-8da9-bb1513638c29","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# DataFrames and Transformations Review\n## De-Duping Data Lab\n\nIn this exercise, we're doing ETL on a file we've received from a customer. That file contains data about people, including:\n\n* first, middle and last names\n* gender\n* birth date\n* Social Security number\n* salary\n\nBut, as is unfortunately common in data we get from this customer, the file contains some duplicate records. Worse:\n\n* In some of the records, the names are mixed case (e.g., \"Carol\"), while in others, they are uppercase (e.g., \"CAROL\").\n* The Social Security numbers aren't consistent either. Some of them are hyphenated (e.g., \"992-83-4829\"), while others are missing hyphens (\"992834829\").\n\nIf all of the name fields match -- if you disregard character case -- then the birth dates and salaries are guaranteed to match as well,\nand the Social Security Numbers *would* match if they were somehow put in the same format.\n\nYour job is to remove the duplicate records. The specific requirements of your job are:\n\n* Remove duplicates. It doesn't matter which record you keep; it only matters that you keep one of them.\n* Preserve the data format of the columns. For example, if you write the first name column in all lowercase, you haven't met this requirement.\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> The initial dataset contains 103,000 records.\nThe de-duplicated result has 100,000 records.\n\nNext, write the results in **Delta** format as a **single data file** to the directory given by the variable *deltaDestDir*.\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> Remember the relationship between the number of partitions in a DataFrame and the number of files written.\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameReader</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html?#functions\" target=\"_blank\">Built-In Functions</a>\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#input-and-output\" target=\"_blank\">DataFrameWriter</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"166692d3-8ef5-44cd-b3d3-1f58fcab2853","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4114afa7-3eca-4677-b98c-7d9861dc3a6a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["It's helpful to look at the file first, so you can check the format. `dbutils.fs.head()` (or just `%fs head`) is a big help here."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8beeec4e-0ee9-4faa-adae-ebc322fe8fdf","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%fs head dbfs:/mnt/training/dataframes/people-with-dups.txt"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c70acfab-d316-4ebf-a678-6bfaff7c4b62","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# TODO\n\nsourceFile = \"dbfs:/mnt/training/dataframes/people-with-dups.txt\"\ndestFile = workingDir + \"/people.parquet\"\n\n# In case it already exists\ndbutils.fs.rm(destFile, True)\n\n# Complete your work here...\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"13d7cd0c-9b9f-45de-8a80-8c20f4683c8d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"600bc335-3985-4267-8bcb-48a7588a5bd4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["verify_files = dbutils.fs.ls(deltaDestDir)\nverify_delta_format = False\nverify_num_data_files = 0\nfor f in verify_files:\n    if f.name == '_delta_log/':\n        verify_delta_format = True\n    elif f.name.endswith('.parquet'):\n        verify_num_data_files += 1\n\nassert verify_delta_format, \"Data not written in Delta format\"\nassert verify_num_data_files == 1, \"Expected 1 data file written\"\n\nverify_record_count = spark.read.format(\"delta\").load(deltaDestDir).count()\nassert verify_record_count == 100000, \"Expected 100000 records in final result\"\n\ndel verify_files, verify_delta_format, verify_num_data_files, verify_record_count"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4ec6bedc-b959-45ef-ad52-acce3765f6a6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Clean up classroom\nRun the cell below to clean up resources."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"afad540f-da94-4bc7-8313-3a2d6838556e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Cleanup\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1777597e-9116-479a-a14d-a6d8fecffa84","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c0ebf93-a2d4-4fed-a05d-6ae254df156e","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 3.4 - Review","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
