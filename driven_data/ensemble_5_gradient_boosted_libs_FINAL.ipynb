{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42a826dc-641b-42ed-a75a-ebf4844e40d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2661d786-5633-4871-bfcd-2ef1580689ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ydf\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ed6e974-a699-4d93-ab8e-2a037fddb2a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# training p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbbbd90d-3d6e-47af-a11c-86552c65c17e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#data\n",
    "train = pd.read_csv(\"data/train_features.csv\")\n",
    "y = pd.read_csv(\"data/train_labels.csv\")\n",
    "test = pd.read_csv(\"data/test_features.csv\")\n",
    "ss = pd.read_csv(\"data/submission_format.csv\")\n",
    "\n",
    "merged_df = pd.merge(train, y, on='uid', how='left')\n",
    "merged_test = pd.merge(test, ss, on='uid', how='left')\n",
    "\n",
    "def feature_engineering(data):\n",
    "    data['rjob_hrswk_change'] = (data['rjob_hrswk_12'] - data['rjob_hrswk_03']).astype(float)\n",
    "    data['max_work_year'] = data[['rjob_end_12','rjob_end_03']].max(axis=1).astype(float)\n",
    "    data['years_since_work'] = (data['year'] - data['max_work_year']).astype(float)\n",
    "    data['hincome_change'] = (data['hincome_12'] - data['hincome_03']).astype(float)\n",
    "    data['niadl_change'] = (data['n_iadl_12'] - data['n_iadl_03']).astype(float)\n",
    "    data['adl_change'] = (data['n_adl_12'] - data['n_adl_03']).astype(float)\n",
    "    data['depr_change'] = (data['n_depr_12'] - data['n_depr_03']).astype(float)\n",
    "\n",
    "    data['glob_hlth_03']=data['glob_hlth_03'].replace({\n",
    "        '5. Poor':0, '4. Fair':1, '3. Good':2, '2. Very good':3, '1. Excellent':4}).astype(float)\n",
    "    data['glob_hlth_12']=data['glob_hlth_12'].replace({\n",
    "        '5. Poor':0, '4. Fair':1, '3. Good':2, '2. Very good':3, '1. Excellent':4}).astype(float)\n",
    "    data['glob_hlth_change']=(data['glob_hlth_12'] - data['glob_hlth_03']).astype(float)\n",
    "\n",
    "    data['bmi_03']=data['bmi_03'].replace({\n",
    "        '1. Underweight':1, '2. Normal weight':2, '3. Overweight':3, '4. Obese':4, '5. Morbidly obese':5}).astype(float)\n",
    "    data['bmi_12']=data['bmi_12'].replace({\n",
    "        '1. Underweight':1, '2. Normal weight':2, '3. Overweight':3, '4. Obese':4, '5. Morbidly obese':5}).astype(float)\n",
    "    data['bmi_change']=(data['bmi_12'] - data['bmi_03']).astype(float)\n",
    "\n",
    "    data['employment_03']=data['employment_03'].replace({\n",
    "        '1. Currently Working':'Working', \n",
    "        '2. Currently looking for work':'Looking for work', \n",
    "        '3. Dedicated to household chores':'House', \n",
    "        '4. Retired, incapacitated, or does not work':'No work'})\n",
    "    data['employment_12']=data['employment_12'].replace({\n",
    "        '1. Currently Working':'Working', \n",
    "        '2. Currently looking for work':'Looking for work', \n",
    "        '3. Dedicated to household chores':'House', \n",
    "        '4. Retired, incapacitated, or does not work':'No work'})\n",
    "\n",
    "    data['memory_12']=data['memory_12'].replace({\n",
    "        '5. Poor':0, '4. Fair':1, '3. Good':2, '2. Very good':3, '1. Excellent':4}).astype(float)\n",
    "\n",
    "    data['edu_gru_03']=data['edu_gru_03'].replace({\n",
    "        '0. No education':0,'1. 1–5 years':1, '2. 6 years':2, '3. 7–9 years':3,'4. 10+ years':4}).astype(float)\n",
    "    data['edu_gru_12']=data['edu_gru_12'].replace({\n",
    "        '0. No education':0,'1. 1–5 years':1, '2. 6 years':2, '3. 7–9 years':3,'4. 10+ years':4}).astype(float)\n",
    "    data['edu_gru_change']=(data['edu_gru_12']-data['edu_gru_03']).astype(float)\n",
    "\n",
    "    data['illnesses_change']=(data['n_illnesses_12'] - data['n_illnesses_03']).astype(float)\n",
    "    return data\n",
    "\n",
    "Y = merged_df['composite_score']\n",
    "data = pd.concat((merged_df, merged_test)).reset_index(drop=True).copy()\n",
    "data = feature_engineering(data)\n",
    "data=data.drop(columns=['uid','composite_score'],axis=1)\n",
    "\n",
    "object_cols = data.select_dtypes(include=['object']).columns\n",
    "for col in object_cols:\n",
    "    data[col] = pd.Categorical(data[col].fillna(\"Missing\"))\n",
    "\n",
    "merged_df = data[:len(Y)]\n",
    "merged_test = data[len(Y):]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "optimized_weights_list = []\n",
    "\n",
    "templates = ydf.GradientBoostedTreesLearner.hyperparameter_templates()\n",
    "ydf_params = templates[\"benchmark_rank1v1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c99c8140-cbe1-4651-9922-25b61b2e1f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# training p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fd3450b-967d-4a52-99e5-8cd1c1db1abd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Fold 1 ==========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007909 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1924\n[LightGBM] [Info] Number of data points in the train set: 3474, number of used features: 195\n[LightGBM] [Info] Start training from score 157.136730\nTraining until validation scores don't improve for 500 rounds\n[100]\tvalid's rmse: 44.2152\n[200]\tvalid's rmse: 40.554\n[300]\tvalid's rmse: 39.0301\n[400]\tvalid's rmse: 38.2889\n[500]\tvalid's rmse: 37.7932\n[600]\tvalid's rmse: 37.4694\n[700]\tvalid's rmse: 37.1953\n[800]\tvalid's rmse: 37.0456\n[900]\tvalid's rmse: 36.9341\n[1000]\tvalid's rmse: 36.8258\n[1100]\tvalid's rmse: 36.7689\n[1200]\tvalid's rmse: 36.7129\n[1300]\tvalid's rmse: 36.6745\n[1400]\tvalid's rmse: 36.686\n[1500]\tvalid's rmse: 36.7099\n[1600]\tvalid's rmse: 36.7041\n[1700]\tvalid's rmse: 36.7297\n[1800]\tvalid's rmse: 36.7263\nEarly stopping, best iteration is:\n[1327]\tvalid's rmse: 36.6658\n0:\tlearn: 61.1063627\ttest: 58.7987195\tbest: 58.7987195 (0)\ttotal: 40.2ms\tremaining: 6m 41s\n100:\tlearn: 45.4018050\ttest: 45.7213248\tbest: 45.7213248 (100)\ttotal: 3.64s\tremaining: 5m 56s\n200:\tlearn: 39.1611918\ttest: 41.5629577\tbest: 41.5629577 (200)\ttotal: 7.29s\tremaining: 5m 55s\n300:\tlearn: 35.6709280\ttest: 39.8673791\tbest: 39.8673791 (300)\ttotal: 11s\tremaining: 5m 55s\n400:\tlearn: 33.4245825\ttest: 39.1252152\tbest: 39.1252152 (400)\ttotal: 14.7s\tremaining: 5m 51s\n500:\tlearn: 31.6828754\ttest: 38.6249708\tbest: 38.6249708 (500)\ttotal: 18.4s\tremaining: 5m 48s\n600:\tlearn: 30.2828383\ttest: 38.3301718\tbest: 38.3301718 (600)\ttotal: 22s\tremaining: 5m 44s\n700:\tlearn: 29.0905266\ttest: 38.0912449\tbest: 38.0912449 (700)\ttotal: 25.7s\tremaining: 5m 41s\n800:\tlearn: 28.1201608\ttest: 37.9189765\tbest: 37.9186493 (797)\ttotal: 29.6s\tremaining: 5m 39s\n900:\tlearn: 27.2881546\ttest: 37.7823027\tbest: 37.7823027 (900)\ttotal: 33.3s\tremaining: 5m 36s\n1000:\tlearn: 26.5601132\ttest: 37.6718643\tbest: 37.6718643 (1000)\ttotal: 37.2s\tremaining: 5m 34s\n1100:\tlearn: 25.8432547\ttest: 37.5451850\tbest: 37.5451850 (1100)\ttotal: 41.2s\tremaining: 5m 33s\n1200:\tlearn: 25.0879363\ttest: 37.4191861\tbest: 37.4191861 (1200)\ttotal: 45.2s\tremaining: 5m 31s\n1300:\tlearn: 24.5114714\ttest: 37.3523100\tbest: 37.3517712 (1299)\ttotal: 49.2s\tremaining: 5m 29s\n1400:\tlearn: 23.8556889\ttest: 37.2772641\tbest: 37.2772641 (1400)\ttotal: 53.2s\tremaining: 5m 26s\n1500:\tlearn: 23.2676141\ttest: 37.1973785\tbest: 37.1971363 (1497)\ttotal: 57.2s\tremaining: 5m 23s\n1600:\tlearn: 22.6316235\ttest: 37.1242786\tbest: 37.1242786 (1600)\ttotal: 1m 1s\tremaining: 5m 21s\n1700:\tlearn: 22.0306706\ttest: 37.0653512\tbest: 37.0653512 (1700)\ttotal: 1m 5s\tremaining: 5m 18s\n1800:\tlearn: 21.4123429\ttest: 37.0181769\tbest: 37.0176532 (1799)\ttotal: 1m 9s\tremaining: 5m 16s\n1900:\tlearn: 20.8287093\ttest: 36.9704238\tbest: 36.9704238 (1900)\ttotal: 1m 13s\tremaining: 5m 13s\n2000:\tlearn: 20.2644220\ttest: 36.9201956\tbest: 36.9190264 (1997)\ttotal: 1m 17s\tremaining: 5m 11s\n2100:\tlearn: 19.7064833\ttest: 36.8830066\tbest: 36.8830066 (2100)\ttotal: 1m 21s\tremaining: 5m 8s\n2200:\tlearn: 19.2060835\ttest: 36.8619674\tbest: 36.8619674 (2200)\ttotal: 1m 26s\tremaining: 5m 5s\n2300:\tlearn: 18.7271193\ttest: 36.8267152\tbest: 36.8249019 (2289)\ttotal: 1m 30s\tremaining: 5m 1s\n2400:\tlearn: 18.2821830\ttest: 36.7843638\tbest: 36.7842804 (2399)\ttotal: 1m 34s\tremaining: 4m 58s\n2500:\tlearn: 17.8336832\ttest: 36.7528661\tbest: 36.7528661 (2500)\ttotal: 1m 38s\tremaining: 4m 55s\n2600:\tlearn: 17.4159685\ttest: 36.7178225\tbest: 36.7154807 (2598)\ttotal: 1m 42s\tremaining: 4m 51s\n2700:\tlearn: 17.0338788\ttest: 36.7020377\tbest: 36.7002880 (2697)\ttotal: 1m 46s\tremaining: 4m 48s\n2800:\tlearn: 16.6899498\ttest: 36.6741071\tbest: 36.6740067 (2789)\ttotal: 1m 50s\tremaining: 4m 44s\n2900:\tlearn: 16.3329726\ttest: 36.6529170\tbest: 36.6501876 (2890)\ttotal: 1m 55s\tremaining: 4m 41s\n3000:\tlearn: 16.0203168\ttest: 36.6361722\tbest: 36.6361722 (3000)\ttotal: 1m 59s\tremaining: 4m 37s\n3100:\tlearn: 15.6554168\ttest: 36.6194663\tbest: 36.6194663 (3100)\ttotal: 2m 3s\tremaining: 4m 34s\n3200:\tlearn: 15.3242391\ttest: 36.6182526\tbest: 36.6154378 (3193)\ttotal: 2m 7s\tremaining: 4m 30s\n3300:\tlearn: 14.9758916\ttest: 36.6059518\tbest: 36.6055823 (3296)\ttotal: 2m 11s\tremaining: 4m 27s\n3400:\tlearn: 14.6417866\ttest: 36.6003520\tbest: 36.5986102 (3360)\ttotal: 2m 15s\tremaining: 4m 23s\n3500:\tlearn: 14.3351357\ttest: 36.5828244\tbest: 36.5823587 (3498)\ttotal: 2m 20s\tremaining: 4m 19s\n3600:\tlearn: 14.0551309\ttest: 36.5710047\tbest: 36.5708821 (3597)\ttotal: 2m 24s\tremaining: 4m 16s\n3700:\tlearn: 13.7383868\ttest: 36.5513628\tbest: 36.5511456 (3697)\ttotal: 2m 28s\tremaining: 4m 12s\n3800:\tlearn: 13.4487215\ttest: 36.5457637\tbest: 36.5453685 (3799)\ttotal: 2m 32s\tremaining: 4m 8s\n3900:\tlearn: 13.1833718\ttest: 36.5383563\tbest: 36.5382966 (3899)\ttotal: 2m 36s\tremaining: 4m 4s\n4000:\tlearn: 12.8751119\ttest: 36.5304218\tbest: 36.5304218 (4000)\ttotal: 2m 40s\tremaining: 4m\n4100:\tlearn: 12.6099469\ttest: 36.5197553\tbest: 36.5197145 (4085)\ttotal: 2m 44s\tremaining: 3m 57s\n4200:\tlearn: 12.3440517\ttest: 36.5125821\tbest: 36.5122701 (4192)\ttotal: 2m 49s\tremaining: 3m 53s\n4300:\tlearn: 12.0916970\ttest: 36.5086202\tbest: 36.5060030 (4242)\ttotal: 2m 53s\tremaining: 3m 49s\n4400:\tlearn: 11.8389277\ttest: 36.5099859\tbest: 36.5056890 (4314)\ttotal: 2m 57s\tremaining: 3m 45s\n4500:\tlearn: 11.6132145\ttest: 36.5125149\tbest: 36.5056890 (4314)\ttotal: 3m 1s\tremaining: 3m 41s\n4600:\tlearn: 11.4122669\ttest: 36.5027846\tbest: 36.5013633 (4598)\ttotal: 3m 5s\tremaining: 3m 37s\n4700:\tlearn: 11.1905402\ttest: 36.4965048\tbest: 36.4965048 (4700)\ttotal: 3m 9s\tremaining: 3m 33s\n4800:\tlearn: 10.9732119\ttest: 36.4905884\tbest: 36.4897357 (4794)\ttotal: 3m 13s\tremaining: 3m 29s\n4900:\tlearn: 10.7756793\ttest: 36.4848277\tbest: 36.4847636 (4899)\ttotal: 3m 18s\tremaining: 3m 26s\n5000:\tlearn: 10.5805070\ttest: 36.4754136\tbest: 36.4751644 (4959)\ttotal: 3m 22s\tremaining: 3m 22s\n5100:\tlearn: 10.3896523\ttest: 36.4675021\tbest: 36.4670118 (5096)\ttotal: 3m 26s\tremaining: 3m 18s\n5200:\tlearn: 10.2154241\ttest: 36.4643949\tbest: 36.4643949 (5200)\ttotal: 3m 30s\tremaining: 3m 14s\n5300:\tlearn: 10.0277983\ttest: 36.4644612\tbest: 36.4619808 (5213)\ttotal: 3m 34s\tremaining: 3m 10s\n5400:\tlearn: 9.8631517\ttest: 36.4682772\tbest: 36.4619808 (5213)\ttotal: 3m 39s\tremaining: 3m 6s\n5500:\tlearn: 9.7143199\ttest: 36.4663267\tbest: 36.4619808 (5213)\ttotal: 3m 43s\tremaining: 3m 2s\n5600:\tlearn: 9.5598397\ttest: 36.4628477\tbest: 36.4619808 (5213)\ttotal: 3m 47s\tremaining: 2m 58s\n5700:\tlearn: 9.3847942\ttest: 36.4543396\tbest: 36.4543396 (5700)\ttotal: 3m 51s\tremaining: 2m 54s\n5800:\tlearn: 9.2294835\ttest: 36.4554525\tbest: 36.4536415 (5787)\ttotal: 3m 55s\tremaining: 2m 50s\n5900:\tlearn: 9.0886046\ttest: 36.4521128\tbest: 36.4508332 (5882)\ttotal: 3m 59s\tremaining: 2m 46s\n6000:\tlearn: 8.9329394\ttest: 36.4458146\tbest: 36.4457065 (5994)\ttotal: 4m 3s\tremaining: 2m 42s\n6100:\tlearn: 8.7882824\ttest: 36.4400284\tbest: 36.4397557 (6092)\ttotal: 4m 8s\tremaining: 2m 38s\n6200:\tlearn: 8.6527807\ttest: 36.4377366\tbest: 36.4363519 (6174)\ttotal: 4m 12s\tremaining: 2m 34s\n6300:\tlearn: 8.5043050\ttest: 36.4367379\tbest: 36.4360962 (6298)\ttotal: 4m 16s\tremaining: 2m 30s\n6400:\tlearn: 8.3834074\ttest: 36.4392399\tbest: 36.4360962 (6298)\ttotal: 4m 20s\tremaining: 2m 26s\n6500:\tlearn: 8.2477693\ttest: 36.4369013\tbest: 36.4351378 (6479)\ttotal: 4m 24s\tremaining: 2m 22s\n6600:\tlearn: 8.1170733\ttest: 36.4299224\tbest: 36.4298876 (6599)\ttotal: 4m 28s\tremaining: 2m 18s\n6700:\tlearn: 7.9959984\ttest: 36.4273543\tbest: 36.4261986 (6678)\ttotal: 4m 32s\tremaining: 2m 14s\n6800:\tlearn: 7.8623158\ttest: 36.4259453\tbest: 36.4241954 (6730)\ttotal: 4m 36s\tremaining: 2m 10s\n6900:\tlearn: 7.7383256\ttest: 36.4247437\tbest: 36.4232076 (6855)\ttotal: 4m 40s\tremaining: 2m 6s\n7000:\tlearn: 7.6226325\ttest: 36.4284216\tbest: 36.4232076 (6855)\ttotal: 4m 45s\tremaining: 2m 2s\n7100:\tlearn: 7.4982183\ttest: 36.4261993\tbest: 36.4232076 (6855)\ttotal: 4m 49s\tremaining: 1m 58s\n7200:\tlearn: 7.3690354\ttest: 36.4224704\tbest: 36.4215189 (7185)\ttotal: 4m 53s\tremaining: 1m 54s\n7300:\tlearn: 7.2413060\ttest: 36.4249093\tbest: 36.4203812 (7214)\ttotal: 4m 57s\tremaining: 1m 49s\n7400:\tlearn: 7.1232952\ttest: 36.4212010\tbest: 36.4203812 (7214)\ttotal: 5m 1s\tremaining: 1m 45s\n7500:\tlearn: 7.0007959\ttest: 36.4197228\tbest: 36.4190125 (7494)\ttotal: 5m 5s\tremaining: 1m 41s\n7600:\tlearn: 6.8726653\ttest: 36.4136076\tbest: 36.4129354 (7585)\ttotal: 5m 9s\tremaining: 1m 37s\n7700:\tlearn: 6.7485389\ttest: 36.4108699\tbest: 36.4085896 (7685)\ttotal: 5m 13s\tremaining: 1m 33s\n7800:\tlearn: 6.6383102\ttest: 36.4108596\tbest: 36.4085896 (7685)\ttotal: 5m 17s\tremaining: 1m 29s\n7900:\tlearn: 6.5051498\ttest: 36.4082170\tbest: 36.4079068 (7833)\ttotal: 5m 22s\tremaining: 1m 25s\n8000:\tlearn: 6.3924275\ttest: 36.4061374\tbest: 36.4048914 (7978)\ttotal: 5m 26s\tremaining: 1m 21s\n8100:\tlearn: 6.2891236\ttest: 36.4063851\tbest: 36.4048914 (7978)\ttotal: 5m 30s\tremaining: 1m 17s\n8200:\tlearn: 6.1818182\ttest: 36.4070768\tbest: 36.4048914 (7978)\ttotal: 5m 34s\tremaining: 1m 13s\n8300:\tlearn: 6.0805403\ttest: 36.4086672\tbest: 36.4048914 (7978)\ttotal: 5m 38s\tremaining: 1m 9s\n8400:\tlearn: 5.9804729\ttest: 36.4080097\tbest: 36.4048914 (7978)\ttotal: 5m 42s\tremaining: 1m 5s\nStopped by overfitting detector  (500 iterations wait)\n\nbestTest = 36.40489136\nbestIteration = 7978\n\nShrink model to first 7979 iterations.\n[0]\tvalidation_0-rmse:58.77700\n[100]\tvalidation_0-rmse:45.86832\n[200]\tvalidation_0-rmse:42.32089\n[300]\tvalidation_0-rmse:40.79543\n[400]\tvalidation_0-rmse:39.94743\n[500]\tvalidation_0-rmse:39.53036\n[600]\tvalidation_0-rmse:39.27665\n[700]\tvalidation_0-rmse:39.08285\n[800]\tvalidation_0-rmse:38.90079\n[900]\tvalidation_0-rmse:38.78109\n[1000]\tvalidation_0-rmse:38.69750\n[1100]\tvalidation_0-rmse:38.63121\n[1200]\tvalidation_0-rmse:38.55950\n[1300]\tvalidation_0-rmse:38.52585\n[1400]\tvalidation_0-rmse:38.49047\n[1500]\tvalidation_0-rmse:38.42440\n[1600]\tvalidation_0-rmse:38.36475\n[1700]\tvalidation_0-rmse:38.31906\n[1800]\tvalidation_0-rmse:38.26835\n[1900]\tvalidation_0-rmse:38.22781\n[2000]\tvalidation_0-rmse:38.18228\n[2100]\tvalidation_0-rmse:38.13738\n[2200]\tvalidation_0-rmse:38.08401\n[2300]\tvalidation_0-rmse:38.04016\n[2400]\tvalidation_0-rmse:37.99269\n[2500]\tvalidation_0-rmse:37.94439\n[2600]\tvalidation_0-rmse:37.90597\n[2700]\tvalidation_0-rmse:37.86533\n[2800]\tvalidation_0-rmse:37.83376\n[2900]\tvalidation_0-rmse:37.81394\n[3000]\tvalidation_0-rmse:37.77655\n[3100]\tvalidation_0-rmse:37.74773\n[3200]\tvalidation_0-rmse:37.72128\n[3300]\tvalidation_0-rmse:37.70841\n[3400]\tvalidation_0-rmse:37.70729\n[3500]\tvalidation_0-rmse:37.69547\n[3600]\tvalidation_0-rmse:37.69304\n[3700]\tvalidation_0-rmse:37.68464\n[3800]\tvalidation_0-rmse:37.68693\n[3900]\tvalidation_0-rmse:37.69270\n[4000]\tvalidation_0-rmse:37.68761\n[4100]\tvalidation_0-rmse:37.68607\n[4183]\tvalidation_0-rmse:37.68721\nTrain model on 3474 examples\nModel trained in 0:00:11.656261\nFold 1 RMSE: 35.927596426511606\n========== Fold 2 ==========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007842 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1918\n[LightGBM] [Info] Number of data points in the train set: 3474, number of used features: 195\n[LightGBM] [Info] Start training from score 157.271445\nTraining until validation scores don't improve for 500 rounds\n[100]\tvalid's rmse: 45.5276\n[200]\tvalid's rmse: 40.5444\n[300]\tvalid's rmse: 38.7598\n[400]\tvalid's rmse: 37.8913\n[500]\tvalid's rmse: 37.5243\n[600]\tvalid's rmse: 37.218\n[700]\tvalid's rmse: 37.0013\n[800]\tvalid's rmse: 36.8715\n[900]\tvalid's rmse: 36.76\n[1000]\tvalid's rmse: 36.6967\n[1100]\tvalid's rmse: 36.6146\n[1200]\tvalid's rmse: 36.557\n[1300]\tvalid's rmse: 36.5015\n[1400]\tvalid's rmse: 36.4897\n[1500]\tvalid's rmse: 36.4513\n[1600]\tvalid's rmse: 36.4412\n[1700]\tvalid's rmse: 36.4359\n[1800]\tvalid's rmse: 36.4388\n[1900]\tvalid's rmse: 36.4367\n[2000]\tvalid's rmse: 36.4755\n[2100]\tvalid's rmse: 36.469\n[2200]\tvalid's rmse: 36.4425\n[2300]\tvalid's rmse: 36.4253\n[2400]\tvalid's rmse: 36.4288\n[2500]\tvalid's rmse: 36.4351\n[2600]\tvalid's rmse: 36.4484\n[2700]\tvalid's rmse: 36.4509\nEarly stopping, best iteration is:\n[2284]\tvalid's rmse: 36.4195\n0:\tlearn: 59.9907902\ttest: 63.2094615\tbest: 63.2094615 (0)\ttotal: 37.7ms\tremaining: 6m 17s\n100:\tlearn: 45.1310654\ttest: 47.6070807\tbest: 47.6070807 (100)\ttotal: 3.57s\tremaining: 5m 49s\n200:\tlearn: 38.9875127\ttest: 42.4352906\tbest: 42.4352906 (200)\ttotal: 7.25s\tremaining: 5m 53s\n300:\tlearn: 35.5235392\ttest: 40.2150772\tbest: 40.2150772 (300)\ttotal: 10.9s\tremaining: 5m 50s\n400:\tlearn: 33.1813938\ttest: 39.1194870\tbest: 39.1194870 (400)\ttotal: 14.6s\tremaining: 5m 48s\n500:\tlearn: 31.5564557\ttest: 38.5151816\tbest: 38.5151816 (500)\ttotal: 18.3s\tremaining: 5m 46s\n600:\tlearn: 30.1657989\ttest: 38.1346801\tbest: 38.1346801 (600)\ttotal: 22s\tremaining: 5m 44s\n700:\tlearn: 28.9884767\ttest: 37.8868718\tbest: 37.8868718 (700)\ttotal: 25.7s\tremaining: 5m 40s\n800:\tlearn: 27.9626990\ttest: 37.6847878\tbest: 37.6847878 (800)\ttotal: 29.6s\tremaining: 5m 39s\n900:\tlearn: 27.0020625\ttest: 37.5285275\tbest: 37.5285275 (900)\ttotal: 33.5s\tremaining: 5m 37s\n1000:\tlearn: 26.1789213\ttest: 37.3949454\tbest: 37.3949454 (1000)\ttotal: 37.4s\tremaining: 5m 36s\n1100:\tlearn: 25.2739659\ttest: 37.2801841\tbest: 37.2801841 (1100)\ttotal: 41.4s\tremaining: 5m 34s\n1200:\tlearn: 24.5910880\ttest: 37.1738886\tbest: 37.1738886 (1200)\ttotal: 45.5s\tremaining: 5m 33s\n1300:\tlearn: 23.9229557\ttest: 37.1011125\tbest: 37.1011125 (1300)\ttotal: 49.6s\tremaining: 5m 31s\n1400:\tlearn: 23.2107274\ttest: 37.0359035\tbest: 37.0338701 (1394)\ttotal: 53.6s\tremaining: 5m 29s\n1500:\tlearn: 22.4723053\ttest: 36.9681937\tbest: 36.9681937 (1500)\ttotal: 57.8s\tremaining: 5m 27s\n1600:\tlearn: 21.7900849\ttest: 36.8963978\tbest: 36.8963978 (1600)\ttotal: 1m 1s\tremaining: 5m 24s\n1700:\tlearn: 21.1769653\ttest: 36.8317941\tbest: 36.8317941 (1700)\ttotal: 1m 5s\tremaining: 5m 21s\n1800:\tlearn: 20.6030087\ttest: 36.7861175\tbest: 36.7861175 (1800)\ttotal: 1m 10s\tremaining: 5m 18s\n1900:\tlearn: 20.0193219\ttest: 36.7312130\tbest: 36.7304825 (1898)\ttotal: 1m 14s\tremaining: 5m 15s\n2000:\tlearn: 19.5513313\ttest: 36.6885105\tbest: 36.6883625 (1999)\ttotal: 1m 18s\tremaining: 5m 13s\n2100:\tlearn: 19.0681863\ttest: 36.6502640\tbest: 36.6495567 (2096)\ttotal: 1m 22s\tremaining: 5m 9s\n2200:\tlearn: 18.6045094\ttest: 36.6120420\tbest: 36.6115132 (2199)\ttotal: 1m 26s\tremaining: 5m 6s\n2300:\tlearn: 18.1793490\ttest: 36.5778623\tbest: 36.5768814 (2292)\ttotal: 1m 30s\tremaining: 5m 3s\n2400:\tlearn: 17.7048012\ttest: 36.5463645\tbest: 36.5409355 (2387)\ttotal: 1m 34s\tremaining: 5m\n2500:\tlearn: 17.2999409\ttest: 36.5265045\tbest: 36.5237537 (2494)\ttotal: 1m 39s\tremaining: 4m 57s\n2600:\tlearn: 16.8953681\ttest: 36.4961068\tbest: 36.4961068 (2600)\ttotal: 1m 43s\tremaining: 4m 53s\n2700:\tlearn: 16.5428661\ttest: 36.4791450\tbest: 36.4791450 (2700)\ttotal: 1m 47s\tremaining: 4m 50s\n2800:\tlearn: 16.1688695\ttest: 36.4612613\tbest: 36.4608686 (2793)\ttotal: 1m 51s\tremaining: 4m 46s\n2900:\tlearn: 15.8076183\ttest: 36.4404568\tbest: 36.4400381 (2890)\ttotal: 1m 55s\tremaining: 4m 43s\n3000:\tlearn: 15.4547479\ttest: 36.4253251\tbest: 36.4249902 (2990)\ttotal: 1m 59s\tremaining: 4m 39s\n3100:\tlearn: 15.1365554\ttest: 36.4153550\tbest: 36.4129423 (3072)\ttotal: 2m 4s\tremaining: 4m 36s\n3200:\tlearn: 14.7879822\ttest: 36.4001245\tbest: 36.3997037 (3199)\ttotal: 2m 8s\tremaining: 4m 32s\n3300:\tlearn: 14.4672965\ttest: 36.3846611\tbest: 36.3846611 (3300)\ttotal: 2m 12s\tremaining: 4m 28s\n3400:\tlearn: 14.1469940\ttest: 36.3681624\tbest: 36.3670616 (3395)\ttotal: 2m 16s\tremaining: 4m 25s\n3500:\tlearn: 13.8277447\ttest: 36.3588251\tbest: 36.3545265 (3470)\ttotal: 2m 20s\tremaining: 4m 21s\n3600:\tlearn: 13.5311917\ttest: 36.3511320\tbest: 36.3511320 (3600)\ttotal: 2m 25s\tremaining: 4m 17s\n3700:\tlearn: 13.2854990\ttest: 36.3447670\tbest: 36.3447299 (3695)\ttotal: 2m 29s\tremaining: 4m 13s\n3800:\tlearn: 13.0163706\ttest: 36.3457997\tbest: 36.3412732 (3743)\ttotal: 2m 33s\tremaining: 4m 10s\n3900:\tlearn: 12.7409523\ttest: 36.3409790\tbest: 36.3403734 (3896)\ttotal: 2m 37s\tremaining: 4m 6s\n4000:\tlearn: 12.4728173\ttest: 36.3282538\tbest: 36.3267504 (3995)\ttotal: 2m 41s\tremaining: 4m 2s\n4100:\tlearn: 12.2375275\ttest: 36.3237203\tbest: 36.3226103 (4077)\ttotal: 2m 45s\tremaining: 3m 58s\n4200:\tlearn: 12.0168977\ttest: 36.3191085\tbest: 36.3160062 (4183)\ttotal: 2m 50s\tremaining: 3m 54s\n4300:\tlearn: 11.7894965\ttest: 36.3155086\tbest: 36.3135651 (4293)\ttotal: 2m 54s\tremaining: 3m 51s\n4400:\tlearn: 11.5743875\ttest: 36.3217897\tbest: 36.3135651 (4293)\ttotal: 2m 58s\tremaining: 3m 47s\n4500:\tlearn: 11.3726377\ttest: 36.3272920\tbest: 36.3135651 (4293)\ttotal: 3m 2s\tremaining: 3m 43s\n4600:\tlearn: 11.1520175\ttest: 36.3301030\tbest: 36.3135651 (4293)\ttotal: 3m 6s\tremaining: 3m 39s\n4700:\tlearn: 10.9414716\ttest: 36.3368980\tbest: 36.3135651 (4293)\ttotal: 3m 11s\tremaining: 3m 35s\nStopped by overfitting detector  (500 iterations wait)\n\nbestTest = 36.31356508\nbestIteration = 4293\n\nShrink model to first 4294 iterations.\n[0]\tvalidation_0-rmse:63.17007\n[100]\tvalidation_0-rmse:47.40418\n[200]\tvalidation_0-rmse:42.70518\n[300]\tvalidation_0-rmse:40.81539\n[400]\tvalidation_0-rmse:39.93084\n[500]\tvalidation_0-rmse:39.46957\n[600]\tvalidation_0-rmse:39.17220\n[700]\tvalidation_0-rmse:39.00297\n[800]\tvalidation_0-rmse:38.85987\n[900]\tvalidation_0-rmse:38.75698\n[1000]\tvalidation_0-rmse:38.65962\n[1100]\tvalidation_0-rmse:38.55989\n[1200]\tvalidation_0-rmse:38.49445\n[1300]\tvalidation_0-rmse:38.42029\n[1400]\tvalidation_0-rmse:38.35200\n[1500]\tvalidation_0-rmse:38.28205\n[1600]\tvalidation_0-rmse:38.22644\n[1700]\tvalidation_0-rmse:38.16844\n[1800]\tvalidation_0-rmse:38.11379\n[1900]\tvalidation_0-rmse:38.08466\n[2000]\tvalidation_0-rmse:38.03793\n[2100]\tvalidation_0-rmse:37.98479\n[2200]\tvalidation_0-rmse:37.93565\n[2300]\tvalidation_0-rmse:37.90794\n[2400]\tvalidation_0-rmse:37.88449\n[2500]\tvalidation_0-rmse:37.85838\n[2600]\tvalidation_0-rmse:37.83728\n[2700]\tvalidation_0-rmse:37.81999\n[2800]\tvalidation_0-rmse:37.79840\n[2900]\tvalidation_0-rmse:37.80404\n[3000]\tvalidation_0-rmse:37.81509\n[3100]\tvalidation_0-rmse:37.81095\n[3200]\tvalidation_0-rmse:37.84249\n[3300]\tvalidation_0-rmse:37.82886\n[3301]\tvalidation_0-rmse:37.82763\nTrain model on 3474 examples\nModel trained in 0:00:12.306352\nFold 2 RMSE: 35.876236626212915\n========== Fold 3 ==========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016473 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1932\n[LightGBM] [Info] Number of data points in the train set: 3474, number of used features: 195\n[LightGBM] [Info] Start training from score 156.375360\nTraining until validation scores don't improve for 500 rounds\n[100]\tvalid's rmse: 45.4773\n[200]\tvalid's rmse: 41.9952\n[300]\tvalid's rmse: 40.7429\n[400]\tvalid's rmse: 40.1255\n[500]\tvalid's rmse: 39.8105\n[600]\tvalid's rmse: 39.6052\n[700]\tvalid's rmse: 39.4801\n[800]\tvalid's rmse: 39.321\n[900]\tvalid's rmse: 39.2487\n[1000]\tvalid's rmse: 39.1792\n[1100]\tvalid's rmse: 39.1557\n[1200]\tvalid's rmse: 39.1131\n[1300]\tvalid's rmse: 39.0614\n[1400]\tvalid's rmse: 39.047\n[1500]\tvalid's rmse: 39.0166\n[1600]\tvalid's rmse: 39.0289\n[1700]\tvalid's rmse: 39.0461\n[1800]\tvalid's rmse: 39.0231\n[1900]\tvalid's rmse: 39.0052\n[2000]\tvalid's rmse: 38.9936\n[2100]\tvalid's rmse: 38.9895\n[2200]\tvalid's rmse: 39.0084\n[2300]\tvalid's rmse: 39.0066\n[2400]\tvalid's rmse: 39.0136\n[2500]\tvalid's rmse: 39.0462\nEarly stopping, best iteration is:\n[2065]\tvalid's rmse: 38.9767\n0:\tlearn: 60.9116757\ttest: 59.6139346\tbest: 59.6139346 (0)\ttotal: 40ms\tremaining: 6m 39s\n100:\tlearn: 45.2551866\ttest: 46.8663004\tbest: 46.8663004 (100)\ttotal: 3.59s\tremaining: 5m 51s\n200:\tlearn: 39.0381907\ttest: 42.8832168\tbest: 42.8832168 (200)\ttotal: 7.31s\tremaining: 5m 56s\n300:\tlearn: 35.5866766\ttest: 41.2763239\tbest: 41.2763239 (300)\ttotal: 11.1s\tremaining: 5m 58s\n400:\tlearn: 33.2124296\ttest: 40.4566551\tbest: 40.4566551 (400)\ttotal: 14.9s\tremaining: 5m 57s\n500:\tlearn: 31.4563911\ttest: 39.9630781\tbest: 39.9630781 (500)\ttotal: 18.7s\tremaining: 5m 54s\n600:\tlearn: 30.0788486\ttest: 39.6401711\tbest: 39.6401711 (600)\ttotal: 22.5s\tremaining: 5m 52s\n700:\tlearn: 28.8538656\ttest: 39.3996568\tbest: 39.3996568 (700)\ttotal: 26.4s\tremaining: 5m 49s\n800:\tlearn: 27.7510599\ttest: 39.2196675\tbest: 39.2196675 (800)\ttotal: 30.2s\tremaining: 5m 46s\n900:\tlearn: 26.7858254\ttest: 39.0791816\tbest: 39.0791816 (900)\ttotal: 34.1s\tremaining: 5m 44s\n1000:\tlearn: 25.8619697\ttest: 38.9420669\tbest: 38.9420669 (1000)\ttotal: 38.1s\tremaining: 5m 42s\n1100:\tlearn: 25.0546035\ttest: 38.8494228\tbest: 38.8494228 (1100)\ttotal: 42.1s\tremaining: 5m 40s\n1200:\tlearn: 24.2995565\ttest: 38.7633846\tbest: 38.7633846 (1200)\ttotal: 46.2s\tremaining: 5m 38s\n1300:\tlearn: 23.4295372\ttest: 38.6470881\tbest: 38.6470881 (1300)\ttotal: 50.2s\tremaining: 5m 35s\n1400:\tlearn: 22.6651172\ttest: 38.5697838\tbest: 38.5697838 (1400)\ttotal: 54.2s\tremaining: 5m 32s\n1500:\tlearn: 21.9476878\ttest: 38.5016027\tbest: 38.5006733 (1498)\ttotal: 58.3s\tremaining: 5m 30s\n1600:\tlearn: 21.2838135\ttest: 38.4652003\tbest: 38.4640166 (1590)\ttotal: 1m 2s\tremaining: 5m 27s\n1700:\tlearn: 20.6833984\ttest: 38.4165939\tbest: 38.4162533 (1699)\ttotal: 1m 6s\tremaining: 5m 25s\n1800:\tlearn: 20.1172286\ttest: 38.3836982\tbest: 38.3836982 (1800)\ttotal: 1m 10s\tremaining: 5m 22s\n1900:\tlearn: 19.5815354\ttest: 38.3412120\tbest: 38.3412120 (1900)\ttotal: 1m 14s\tremaining: 5m 18s\n2000:\tlearn: 19.0287136\ttest: 38.2891162\tbest: 38.2891162 (2000)\ttotal: 1m 18s\tremaining: 5m 15s\n2100:\tlearn: 18.5532187\ttest: 38.2534880\tbest: 38.2528913 (2094)\ttotal: 1m 23s\tremaining: 5m 12s\n2200:\tlearn: 18.1050653\ttest: 38.2071525\tbest: 38.2071525 (2200)\ttotal: 1m 27s\tremaining: 5m 8s\n2300:\tlearn: 17.6978431\ttest: 38.1794114\tbest: 38.1793616 (2299)\ttotal: 1m 31s\tremaining: 5m 5s\n2400:\tlearn: 17.2715827\ttest: 38.1620969\tbest: 38.1593886 (2394)\ttotal: 1m 35s\tremaining: 5m 1s\n2500:\tlearn: 16.9103913\ttest: 38.1430912\tbest: 38.1421832 (2498)\ttotal: 1m 39s\tremaining: 4m 58s\n2600:\tlearn: 16.5556814\ttest: 38.1069357\tbest: 38.1069357 (2600)\ttotal: 1m 43s\tremaining: 4m 54s\n2700:\tlearn: 16.1266450\ttest: 38.0832023\tbest: 38.0832023 (2700)\ttotal: 1m 47s\tremaining: 4m 51s\n2800:\tlearn: 15.7845427\ttest: 38.0668410\tbest: 38.0650413 (2792)\ttotal: 1m 51s\tremaining: 4m 47s\n2900:\tlearn: 15.4454913\ttest: 38.0489021\tbest: 38.0481753 (2894)\ttotal: 1m 56s\tremaining: 4m 43s\n3000:\tlearn: 15.1029891\ttest: 38.0322993\tbest: 38.0315504 (2989)\ttotal: 2m\tremaining: 4m 40s\n3100:\tlearn: 14.7750189\ttest: 38.0148789\tbest: 38.0110691 (3093)\ttotal: 2m 4s\tremaining: 4m 36s\n3200:\tlearn: 14.4637473\ttest: 38.0040291\tbest: 38.0040291 (3200)\ttotal: 2m 8s\tremaining: 4m 32s\n3300:\tlearn: 14.1552577\ttest: 37.9865036\tbest: 37.9865036 (3300)\ttotal: 2m 12s\tremaining: 4m 29s\n3400:\tlearn: 13.8648230\ttest: 37.9700725\tbest: 37.9698610 (3386)\ttotal: 2m 16s\tremaining: 4m 25s\n3500:\tlearn: 13.5537841\ttest: 37.9567264\tbest: 37.9554693 (3495)\ttotal: 2m 20s\tremaining: 4m 21s\n3600:\tlearn: 13.2909343\ttest: 37.9421570\tbest: 37.9409096 (3595)\ttotal: 2m 24s\tremaining: 4m 17s\n3700:\tlearn: 12.9882449\ttest: 37.9285925\tbest: 37.9280274 (3689)\ttotal: 2m 28s\tremaining: 4m 13s\n3800:\tlearn: 12.7100583\ttest: 37.9264212\tbest: 37.9256869 (3780)\ttotal: 2m 33s\tremaining: 4m 9s\n3900:\tlearn: 12.4305391\ttest: 37.9062355\tbest: 37.9061142 (3899)\ttotal: 2m 37s\tremaining: 4m 5s\n4000:\tlearn: 12.1264169\ttest: 37.8953746\tbest: 37.8953746 (4000)\ttotal: 2m 41s\tremaining: 4m 1s\n4100:\tlearn: 11.8669558\ttest: 37.8873551\tbest: 37.8854659 (4094)\ttotal: 2m 45s\tremaining: 3m 58s\n4200:\tlearn: 11.5908973\ttest: 37.8825784\tbest: 37.8822273 (4198)\ttotal: 2m 49s\tremaining: 3m 54s\n4300:\tlearn: 11.3361974\ttest: 37.8738469\tbest: 37.8715738 (4295)\ttotal: 2m 53s\tremaining: 3m 50s\n4400:\tlearn: 11.0970233\ttest: 37.8607288\tbest: 37.8587910 (4391)\ttotal: 2m 57s\tremaining: 3m 46s\n4500:\tlearn: 10.9017623\ttest: 37.8593322\tbest: 37.8570512 (4487)\ttotal: 3m 2s\tremaining: 3m 42s\n4600:\tlearn: 10.6960094\ttest: 37.8479908\tbest: 37.8479908 (4600)\ttotal: 3m 6s\tremaining: 3m 38s\n4700:\tlearn: 10.4701961\ttest: 37.8473968\tbest: 37.8434684 (4660)\ttotal: 3m 10s\tremaining: 3m 34s\n4800:\tlearn: 10.2809691\ttest: 37.8367387\tbest: 37.8364196 (4797)\ttotal: 3m 14s\tremaining: 3m 30s\n4900:\tlearn: 10.0653273\ttest: 37.8310238\tbest: 37.8306033 (4897)\ttotal: 3m 18s\tremaining: 3m 26s\n5000:\tlearn: 9.8653093\ttest: 37.8192870\tbest: 37.8188291 (4993)\ttotal: 3m 22s\tremaining: 3m 22s\n5100:\tlearn: 9.6872666\ttest: 37.8083094\tbest: 37.8074537 (5098)\ttotal: 3m 27s\tremaining: 3m 18s\n5200:\tlearn: 9.4950029\ttest: 37.7998495\tbest: 37.7998495 (5200)\ttotal: 3m 31s\tremaining: 3m 14s\n5300:\tlearn: 9.3105076\ttest: 37.7972648\tbest: 37.7967939 (5238)\ttotal: 3m 35s\tremaining: 3m 10s\n5400:\tlearn: 9.1204404\ttest: 37.7967464\tbest: 37.7928618 (5371)\ttotal: 3m 39s\tremaining: 3m 6s\n5500:\tlearn: 8.9458417\ttest: 37.7853655\tbest: 37.7848732 (5497)\ttotal: 3m 43s\tremaining: 3m 2s\n5600:\tlearn: 8.7757699\ttest: 37.7775372\tbest: 37.7762802 (5589)\ttotal: 3m 47s\tremaining: 2m 58s\n5700:\tlearn: 8.6260999\ttest: 37.7758991\tbest: 37.7748496 (5693)\ttotal: 3m 51s\tremaining: 2m 54s\n5800:\tlearn: 8.4678593\ttest: 37.7727100\tbest: 37.7725864 (5798)\ttotal: 3m 56s\tremaining: 2m 50s\n5900:\tlearn: 8.3188016\ttest: 37.7775078\tbest: 37.7722829 (5806)\ttotal: 4m\tremaining: 2m 46s\n6000:\tlearn: 8.1668209\ttest: 37.7715749\tbest: 37.7713264 (5996)\ttotal: 4m 4s\tremaining: 2m 42s\n6100:\tlearn: 8.0136267\ttest: 37.7651764\tbest: 37.7651642 (6096)\ttotal: 4m 8s\tremaining: 2m 38s\n6200:\tlearn: 7.8573984\ttest: 37.7627756\tbest: 37.7624438 (6199)\ttotal: 4m 12s\tremaining: 2m 34s\n6300:\tlearn: 7.7241700\ttest: 37.7577072\tbest: 37.7574129 (6299)\ttotal: 4m 16s\tremaining: 2m 30s\n6400:\tlearn: 7.5798816\ttest: 37.7510183\tbest: 37.7510183 (6400)\ttotal: 4m 21s\tremaining: 2m 26s\n6500:\tlearn: 7.4427083\ttest: 37.7505403\tbest: 37.7499664 (6477)\ttotal: 4m 25s\tremaining: 2m 22s\n6600:\tlearn: 7.3153936\ttest: 37.7480258\tbest: 37.7480258 (6600)\ttotal: 4m 29s\tremaining: 2m 18s\n6700:\tlearn: 7.1810110\ttest: 37.7506841\tbest: 37.7476888 (6601)\ttotal: 4m 33s\tremaining: 2m 14s\n6800:\tlearn: 7.0537606\ttest: 37.7486987\tbest: 37.7467437 (6773)\ttotal: 4m 37s\tremaining: 2m 10s\n6900:\tlearn: 6.9324730\ttest: 37.7461853\tbest: 37.7447025 (6883)\ttotal: 4m 41s\tremaining: 2m 6s\n7000:\tlearn: 6.8229859\ttest: 37.7450686\tbest: 37.7441539 (6993)\ttotal: 4m 45s\tremaining: 2m 2s\n7100:\tlearn: 6.6865944\ttest: 37.7468562\tbest: 37.7441539 (6993)\ttotal: 4m 50s\tremaining: 1m 58s\n7200:\tlearn: 6.5819702\ttest: 37.7484170\tbest: 37.7441539 (6993)\ttotal: 4m 54s\tremaining: 1m 54s\n7300:\tlearn: 6.4658855\ttest: 37.7485384\tbest: 37.7441539 (6993)\ttotal: 4m 58s\tremaining: 1m 50s\n7400:\tlearn: 6.3480046\ttest: 37.7463624\tbest: 37.7441539 (6993)\ttotal: 5m 2s\tremaining: 1m 46s\nStopped by overfitting detector  (500 iterations wait)\n\nbestTest = 37.74415388\nbestIteration = 6993\n\nShrink model to first 6994 iterations.\n[0]\tvalidation_0-rmse:59.59052\n[100]\tvalidation_0-rmse:46.87435\n[200]\tvalidation_0-rmse:43.34095\n[300]\tvalidation_0-rmse:41.89472\n[400]\tvalidation_0-rmse:41.16109\n[500]\tvalidation_0-rmse:40.74059\n[600]\tvalidation_0-rmse:40.48264\n[700]\tvalidation_0-rmse:40.31726\n[800]\tvalidation_0-rmse:40.18951\n[900]\tvalidation_0-rmse:40.11079\n[1000]\tvalidation_0-rmse:40.02462\n[1100]\tvalidation_0-rmse:39.94500\n[1200]\tvalidation_0-rmse:39.88492\n[1300]\tvalidation_0-rmse:39.81741\n[1400]\tvalidation_0-rmse:39.76882\n[1500]\tvalidation_0-rmse:39.71366\n[1600]\tvalidation_0-rmse:39.66257\n[1700]\tvalidation_0-rmse:39.61295\n[1800]\tvalidation_0-rmse:39.57717\n[1900]\tvalidation_0-rmse:39.54128\n[2000]\tvalidation_0-rmse:39.50244\n[2100]\tvalidation_0-rmse:39.46971\n[2200]\tvalidation_0-rmse:39.43502\n[2300]\tvalidation_0-rmse:39.41233\n[2400]\tvalidation_0-rmse:39.39549\n[2500]\tvalidation_0-rmse:39.37579\n[2600]\tvalidation_0-rmse:39.36064\n[2700]\tvalidation_0-rmse:39.34967\n[2800]\tvalidation_0-rmse:39.34740\n[2900]\tvalidation_0-rmse:39.34508\n[3000]\tvalidation_0-rmse:39.34368\n[3100]\tvalidation_0-rmse:39.33467\n[3200]\tvalidation_0-rmse:39.32854\n[3300]\tvalidation_0-rmse:39.31650\n[3400]\tvalidation_0-rmse:39.30878\n[3500]\tvalidation_0-rmse:39.29525\n[3600]\tvalidation_0-rmse:39.28518\n[3700]\tvalidation_0-rmse:39.28206\n[3800]\tvalidation_0-rmse:39.27098\n[3900]\tvalidation_0-rmse:39.26748\n[4000]\tvalidation_0-rmse:39.25649\n[4100]\tvalidation_0-rmse:39.25728\n[4200]\tvalidation_0-rmse:39.25667\n[4300]\tvalidation_0-rmse:39.24910\n[4400]\tvalidation_0-rmse:39.25845\n[4500]\tvalidation_0-rmse:39.26184\n[4600]\tvalidation_0-rmse:39.26137\n[4700]\tvalidation_0-rmse:39.26398\n[4800]\tvalidation_0-rmse:39.26399\n[4803]\tvalidation_0-rmse:39.26501\nTrain model on 3474 examples\nModel trained in 0:00:11.296847\nFold 3 RMSE: 37.679492478563645\n========== Fold 4 ==========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008685 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1924\n[LightGBM] [Info] Number of data points in the train set: 3475, number of used features: 195\n[LightGBM] [Info] Start training from score 157.237122\nTraining until validation scores don't improve for 500 rounds\n[100]\tvalid's rmse: 45.119\n[200]\tvalid's rmse: 40.8769\n[300]\tvalid's rmse: 39.3643\n[400]\tvalid's rmse: 38.7037\n[500]\tvalid's rmse: 38.1786\n[600]\tvalid's rmse: 37.7851\n[700]\tvalid's rmse: 37.5267\n[800]\tvalid's rmse: 37.2898\n[900]\tvalid's rmse: 37.2023\n[1000]\tvalid's rmse: 37.0639\n[1100]\tvalid's rmse: 36.955\n[1200]\tvalid's rmse: 36.8508\n[1300]\tvalid's rmse: 36.807\n[1400]\tvalid's rmse: 36.7527\n[1500]\tvalid's rmse: 36.6901\n[1600]\tvalid's rmse: 36.6676\n[1700]\tvalid's rmse: 36.6405\n[1800]\tvalid's rmse: 36.634\n[1900]\tvalid's rmse: 36.6238\n[2000]\tvalid's rmse: 36.5785\n[2100]\tvalid's rmse: 36.5491\n[2200]\tvalid's rmse: 36.5336\n[2300]\tvalid's rmse: 36.5127\n[2400]\tvalid's rmse: 36.4961\n[2500]\tvalid's rmse: 36.4748\n[2600]\tvalid's rmse: 36.4476\n[2700]\tvalid's rmse: 36.4463\n[2800]\tvalid's rmse: 36.4341\n[2900]\tvalid's rmse: 36.4438\n[3000]\tvalid's rmse: 36.4431\n[3100]\tvalid's rmse: 36.4397\n[3200]\tvalid's rmse: 36.4326\n[3300]\tvalid's rmse: 36.4281\n[3400]\tvalid's rmse: 36.4249\n[3500]\tvalid's rmse: 36.4146\n[3600]\tvalid's rmse: 36.4069\n[3700]\tvalid's rmse: 36.4001\n[3800]\tvalid's rmse: 36.389\n[3900]\tvalid's rmse: 36.3967\n[4000]\tvalid's rmse: 36.3938\n[4100]\tvalid's rmse: 36.3982\n[4200]\tvalid's rmse: 36.4037\n[4300]\tvalid's rmse: 36.3941\nEarly stopping, best iteration is:\n[3802]\tvalid's rmse: 36.3882\n0:\tlearn: 60.6043997\ttest: 60.8094701\tbest: 60.8094701 (0)\ttotal: 39.7ms\tremaining: 6m 36s\n100:\tlearn: 45.2304994\ttest: 46.8621180\tbest: 46.8621180 (100)\ttotal: 3.57s\tremaining: 5m 49s\n200:\tlearn: 39.0570311\ttest: 42.5034486\tbest: 42.5034486 (200)\ttotal: 7.21s\tremaining: 5m 51s\n300:\tlearn: 35.6824354\ttest: 40.7313926\tbest: 40.7313926 (300)\ttotal: 11s\tremaining: 5m 54s\n400:\tlearn: 33.4889507\ttest: 39.9037931\tbest: 39.9037931 (400)\ttotal: 14.7s\tremaining: 5m 51s\n500:\tlearn: 31.7965815\ttest: 39.3931466\tbest: 39.3931466 (500)\ttotal: 18.4s\tremaining: 5m 48s\n600:\tlearn: 30.3798993\ttest: 39.0556815\tbest: 39.0556815 (600)\ttotal: 22.1s\tremaining: 5m 45s\n700:\tlearn: 29.1462259\ttest: 38.7950023\tbest: 38.7950023 (700)\ttotal: 25.9s\tremaining: 5m 43s\n800:\tlearn: 28.1344076\ttest: 38.5992684\tbest: 38.5992684 (800)\ttotal: 29.7s\tremaining: 5m 40s\n900:\tlearn: 27.1589611\ttest: 38.4292030\tbest: 38.4290308 (897)\ttotal: 33.6s\tremaining: 5m 39s\n1000:\tlearn: 26.4320711\ttest: 38.3153082\tbest: 38.3153082 (1000)\ttotal: 37.6s\tremaining: 5m 37s\n1100:\tlearn: 25.6126536\ttest: 38.1805872\tbest: 38.1805872 (1100)\ttotal: 41.7s\tremaining: 5m 37s\n1200:\tlearn: 24.7570987\ttest: 38.0474406\tbest: 38.0474406 (1200)\ttotal: 45.9s\tremaining: 5m 35s\n1300:\tlearn: 23.9859867\ttest: 37.9599479\tbest: 37.9599479 (1300)\ttotal: 50s\tremaining: 5m 34s\n1400:\tlearn: 23.2241881\ttest: 37.8607541\tbest: 37.8605066 (1399)\ttotal: 54.1s\tremaining: 5m 32s\n1500:\tlearn: 22.5083934\ttest: 37.7791271\tbest: 37.7789790 (1499)\ttotal: 58.2s\tremaining: 5m 29s\n1600:\tlearn: 21.7510697\ttest: 37.7123502\tbest: 37.7116391 (1594)\ttotal: 1m 2s\tremaining: 5m 27s\n1700:\tlearn: 21.0454574\ttest: 37.6314546\tbest: 37.6309444 (1696)\ttotal: 1m 6s\tremaining: 5m 24s\n1800:\tlearn: 20.3981911\ttest: 37.5564297\tbest: 37.5559727 (1799)\ttotal: 1m 10s\tremaining: 5m 21s\n1900:\tlearn: 19.7887565\ttest: 37.5056221\tbest: 37.5056221 (1900)\ttotal: 1m 14s\tremaining: 5m 18s\n2000:\tlearn: 19.2523289\ttest: 37.4480604\tbest: 37.4480604 (2000)\ttotal: 1m 18s\tremaining: 5m 15s\n2100:\tlearn: 18.7020391\ttest: 37.3962331\tbest: 37.3960260 (2099)\ttotal: 1m 23s\tremaining: 5m 12s\n2200:\tlearn: 18.1983622\ttest: 37.3575676\tbest: 37.3575676 (2200)\ttotal: 1m 27s\tremaining: 5m 8s\n2300:\tlearn: 17.7165329\ttest: 37.3167205\tbest: 37.3159838 (2291)\ttotal: 1m 31s\tremaining: 5m 5s\n2400:\tlearn: 17.2707856\ttest: 37.2948820\tbest: 37.2948820 (2400)\ttotal: 1m 35s\tremaining: 5m 2s\n2500:\tlearn: 16.8447402\ttest: 37.2644203\tbest: 37.2633790 (2497)\ttotal: 1m 39s\tremaining: 4m 58s\n2600:\tlearn: 16.4134635\ttest: 37.2316495\tbest: 37.2302604 (2595)\ttotal: 1m 43s\tremaining: 4m 55s\n2700:\tlearn: 15.9914059\ttest: 37.1992746\tbest: 37.1980009 (2697)\ttotal: 1m 47s\tremaining: 4m 51s\n2800:\tlearn: 15.5785278\ttest: 37.1685262\tbest: 37.1685262 (2800)\ttotal: 1m 52s\tremaining: 4m 48s\n2900:\tlearn: 15.1826018\ttest: 37.1335487\tbest: 37.1335487 (2900)\ttotal: 1m 56s\tremaining: 4m 44s\n3000:\tlearn: 14.8470120\ttest: 37.1107700\tbest: 37.1107700 (3000)\ttotal: 2m\tremaining: 4m 41s\n3100:\tlearn: 14.4559452\ttest: 37.0893247\tbest: 37.0893247 (3100)\ttotal: 2m 4s\tremaining: 4m 37s\n3200:\tlearn: 14.1069310\ttest: 37.0726488\tbest: 37.0721274 (3199)\ttotal: 2m 8s\tremaining: 4m 33s\n3300:\tlearn: 13.8027622\ttest: 37.0645249\tbest: 37.0645249 (3300)\ttotal: 2m 13s\tremaining: 4m 30s\n3400:\tlearn: 13.4863052\ttest: 37.0547713\tbest: 37.0538597 (3397)\ttotal: 2m 17s\tremaining: 4m 26s\n3500:\tlearn: 13.2032821\ttest: 37.0407893\tbest: 37.0407893 (3500)\ttotal: 2m 21s\tremaining: 4m 22s\n3600:\tlearn: 12.9438902\ttest: 37.0246730\tbest: 37.0244734 (3599)\ttotal: 2m 25s\tremaining: 4m 19s\n3700:\tlearn: 12.7214510\ttest: 37.0163170\tbest: 37.0144918 (3695)\ttotal: 2m 30s\tremaining: 4m 15s\n3800:\tlearn: 12.4767553\ttest: 37.0055185\tbest: 37.0051744 (3777)\ttotal: 2m 34s\tremaining: 4m 11s\n3900:\tlearn: 12.2750958\ttest: 37.0053095\tbest: 37.0038061 (3831)\ttotal: 2m 38s\tremaining: 4m 7s\n4000:\tlearn: 12.0266633\ttest: 37.0015581\tbest: 37.0015581 (4000)\ttotal: 2m 42s\tremaining: 4m 4s\n4100:\tlearn: 11.7770743\ttest: 36.9946152\tbest: 36.9908513 (4080)\ttotal: 2m 46s\tremaining: 4m\n4200:\tlearn: 11.5529558\ttest: 36.9854187\tbest: 36.9854187 (4200)\ttotal: 2m 51s\tremaining: 3m 56s\n4300:\tlearn: 11.3612000\ttest: 36.9764391\tbest: 36.9762867 (4299)\ttotal: 2m 55s\tremaining: 3m 52s\n4400:\tlearn: 11.1857952\ttest: 36.9689988\tbest: 36.9670316 (4352)\ttotal: 2m 59s\tremaining: 3m 48s\n4500:\tlearn: 10.9894449\ttest: 36.9626823\tbest: 36.9614599 (4479)\ttotal: 3m 3s\tremaining: 3m 44s\n4600:\tlearn: 10.7995540\ttest: 36.9607927\tbest: 36.9606310 (4587)\ttotal: 3m 8s\tremaining: 3m 40s\n4700:\tlearn: 10.6178529\ttest: 36.9548804\tbest: 36.9541520 (4689)\ttotal: 3m 12s\tremaining: 3m 36s\n4800:\tlearn: 10.4292882\ttest: 36.9436047\tbest: 36.9434259 (4791)\ttotal: 3m 16s\tremaining: 3m 33s\n4900:\tlearn: 10.2606043\ttest: 36.9384889\tbest: 36.9381320 (4885)\ttotal: 3m 20s\tremaining: 3m 29s\n5000:\tlearn: 10.1071057\ttest: 36.9296630\tbest: 36.9294959 (4999)\ttotal: 3m 25s\tremaining: 3m 25s\n5100:\tlearn: 9.9432274\ttest: 36.9299507\tbest: 36.9283111 (5028)\ttotal: 3m 29s\tremaining: 3m 21s\n5200:\tlearn: 9.7998378\ttest: 36.9278547\tbest: 36.9278198 (5198)\ttotal: 3m 33s\tremaining: 3m 17s\n5300:\tlearn: 9.6379611\ttest: 36.9249613\tbest: 36.9244207 (5297)\ttotal: 3m 37s\tremaining: 3m 13s\n5400:\tlearn: 9.4930051\ttest: 36.9212937\tbest: 36.9201758 (5382)\ttotal: 3m 41s\tremaining: 3m 8s\n5500:\tlearn: 9.3327246\ttest: 36.9164338\tbest: 36.9163216 (5496)\ttotal: 3m 46s\tremaining: 3m 4s\n5600:\tlearn: 9.1678677\ttest: 36.9177789\tbest: 36.9163216 (5496)\ttotal: 3m 50s\tremaining: 3m\n5700:\tlearn: 9.0355429\ttest: 36.9164011\tbest: 36.9136448 (5659)\ttotal: 3m 54s\tremaining: 2m 56s\n5800:\tlearn: 8.8876264\ttest: 36.9135699\tbest: 36.9131968 (5777)\ttotal: 3m 58s\tremaining: 2m 52s\n5900:\tlearn: 8.7443398\ttest: 36.9113097\tbest: 36.9105214 (5896)\ttotal: 4m 2s\tremaining: 2m 48s\n6000:\tlearn: 8.6423110\ttest: 36.9096317\tbest: 36.9096317 (6000)\ttotal: 4m 7s\tremaining: 2m 44s\n6100:\tlearn: 8.4969697\ttest: 36.9061562\tbest: 36.9059138 (6096)\ttotal: 4m 11s\tremaining: 2m 40s\n6200:\tlearn: 8.3622191\ttest: 36.9033498\tbest: 36.9023971 (6145)\ttotal: 4m 15s\tremaining: 2m 36s\n6300:\tlearn: 8.2567373\ttest: 36.8983416\tbest: 36.8981212 (6298)\ttotal: 4m 19s\tremaining: 2m 32s\n6400:\tlearn: 8.1416633\ttest: 36.8927536\tbest: 36.8927405 (6397)\ttotal: 4m 23s\tremaining: 2m 28s\n6500:\tlearn: 8.0365918\ttest: 36.8938773\tbest: 36.8912402 (6466)\ttotal: 4m 28s\tremaining: 2m 24s\n6600:\tlearn: 7.9202118\ttest: 36.8951158\tbest: 36.8912402 (6466)\ttotal: 4m 32s\tremaining: 2m 20s\n6700:\tlearn: 7.7998065\ttest: 36.8926170\tbest: 36.8907357 (6679)\ttotal: 4m 36s\tremaining: 2m 16s\n6800:\tlearn: 7.6887332\ttest: 36.8970592\tbest: 36.8907357 (6679)\ttotal: 4m 40s\tremaining: 2m 12s\n6900:\tlearn: 7.5636499\ttest: 36.8964219\tbest: 36.8907357 (6679)\ttotal: 4m 45s\tremaining: 2m 7s\n7000:\tlearn: 7.4592894\ttest: 36.8939375\tbest: 36.8907357 (6679)\ttotal: 4m 49s\tremaining: 2m 3s\n7100:\tlearn: 7.3654372\ttest: 36.8906570\tbest: 36.8906570 (7100)\ttotal: 4m 53s\tremaining: 1m 59s\n7200:\tlearn: 7.2630368\ttest: 36.8877351\tbest: 36.8866525 (7156)\ttotal: 4m 57s\tremaining: 1m 55s\n7300:\tlearn: 7.1706114\ttest: 36.8850707\tbest: 36.8850541 (7299)\ttotal: 5m 1s\tremaining: 1m 51s\n7400:\tlearn: 7.0896186\ttest: 36.8852571\tbest: 36.8840270 (7359)\ttotal: 5m 6s\tremaining: 1m 47s\n7500:\tlearn: 6.9915237\ttest: 36.8806738\tbest: 36.8806674 (7471)\ttotal: 5m 10s\tremaining: 1m 43s\n7600:\tlearn: 6.8872494\ttest: 36.8754182\tbest: 36.8750967 (7578)\ttotal: 5m 14s\tremaining: 1m 39s\n7700:\tlearn: 6.7941296\ttest: 36.8743069\tbest: 36.8725543 (7671)\ttotal: 5m 18s\tremaining: 1m 35s\n7800:\tlearn: 6.7056360\ttest: 36.8734683\tbest: 36.8725483 (7754)\ttotal: 5m 22s\tremaining: 1m 30s\n7900:\tlearn: 6.6253943\ttest: 36.8688846\tbest: 36.8688136 (7899)\ttotal: 5m 26s\tremaining: 1m 26s\n8000:\tlearn: 6.5419986\ttest: 36.8718696\tbest: 36.8687401 (7909)\ttotal: 5m 31s\tremaining: 1m 22s\n8100:\tlearn: 6.4572192\ttest: 36.8702172\tbest: 36.8687401 (7909)\ttotal: 5m 35s\tremaining: 1m 18s\n8200:\tlearn: 6.3712962\ttest: 36.8665750\tbest: 36.8663630 (8165)\ttotal: 5m 39s\tremaining: 1m 14s\n8300:\tlearn: 6.2887840\ttest: 36.8671568\tbest: 36.8660094 (8265)\ttotal: 5m 43s\tremaining: 1m 10s\n8400:\tlearn: 6.1924493\ttest: 36.8673015\tbest: 36.8660094 (8265)\ttotal: 5m 47s\tremaining: 1m 6s\n8500:\tlearn: 6.1042034\ttest: 36.8651084\tbest: 36.8642145 (8460)\ttotal: 5m 51s\tremaining: 1m 2s\n8600:\tlearn: 6.0292474\ttest: 36.8646674\tbest: 36.8639544 (8596)\ttotal: 5m 55s\tremaining: 57.9s\n8700:\tlearn: 5.9565626\ttest: 36.8646246\tbest: 36.8639544 (8596)\ttotal: 6m\tremaining: 53.8s\n8800:\tlearn: 5.8776997\ttest: 36.8655701\tbest: 36.8639544 (8596)\ttotal: 6m 4s\tremaining: 49.6s\n8900:\tlearn: 5.7994378\ttest: 36.8667238\tbest: 36.8639544 (8596)\ttotal: 6m 8s\tremaining: 45.5s\n9000:\tlearn: 5.7310817\ttest: 36.8648677\tbest: 36.8639544 (8596)\ttotal: 6m 12s\tremaining: 41.3s\n9100:\tlearn: 5.6456126\ttest: 36.8626282\tbest: 36.8621129 (9094)\ttotal: 6m 16s\tremaining: 37.2s\n9200:\tlearn: 5.5626598\ttest: 36.8615372\tbest: 36.8612819 (9198)\ttotal: 6m 20s\tremaining: 33.1s\n9300:\tlearn: 5.4947242\ttest: 36.8593270\tbest: 36.8589712 (9286)\ttotal: 6m 24s\tremaining: 28.9s\n9400:\tlearn: 5.4272620\ttest: 36.8617672\tbest: 36.8589104 (9356)\ttotal: 6m 29s\tremaining: 24.8s\n9500:\tlearn: 5.3427433\ttest: 36.8607005\tbest: 36.8589104 (9356)\ttotal: 6m 33s\tremaining: 20.7s\n9600:\tlearn: 5.2713905\ttest: 36.8625673\tbest: 36.8589104 (9356)\ttotal: 6m 37s\tremaining: 16.5s\n9700:\tlearn: 5.2008701\ttest: 36.8639384\tbest: 36.8589104 (9356)\ttotal: 6m 41s\tremaining: 12.4s\n9800:\tlearn: 5.1340905\ttest: 36.8649672\tbest: 36.8589104 (9356)\ttotal: 6m 45s\tremaining: 8.23s\nStopped by overfitting detector  (500 iterations wait)\n\nbestTest = 36.85891042\nbestIteration = 9356\n\nShrink model to first 9357 iterations.\n[0]\tvalidation_0-rmse:60.77724\n[100]\tvalidation_0-rmse:46.91135\n[200]\tvalidation_0-rmse:43.12649\n[300]\tvalidation_0-rmse:41.58477\n[400]\tvalidation_0-rmse:40.78114\n[500]\tvalidation_0-rmse:40.31230\n[600]\tvalidation_0-rmse:40.00877\n[700]\tvalidation_0-rmse:39.77871\n[800]\tvalidation_0-rmse:39.64332\n[900]\tvalidation_0-rmse:39.57374\n[1000]\tvalidation_0-rmse:39.50706\n[1100]\tvalidation_0-rmse:39.45727\n[1200]\tvalidation_0-rmse:39.41307\n[1300]\tvalidation_0-rmse:39.36814\n[1400]\tvalidation_0-rmse:39.33533\n[1500]\tvalidation_0-rmse:39.28987\n[1600]\tvalidation_0-rmse:39.17589\n[1700]\tvalidation_0-rmse:39.06637\n[1800]\tvalidation_0-rmse:38.99101\n[1900]\tvalidation_0-rmse:38.94468\n[2000]\tvalidation_0-rmse:38.88892\n[2100]\tvalidation_0-rmse:38.82742\n[2200]\tvalidation_0-rmse:38.77338\n[2300]\tvalidation_0-rmse:38.71348\n[2400]\tvalidation_0-rmse:38.65210\n[2500]\tvalidation_0-rmse:38.60781\n[2600]\tvalidation_0-rmse:38.55549\n[2700]\tvalidation_0-rmse:38.50320\n[2800]\tvalidation_0-rmse:38.46236\n[2900]\tvalidation_0-rmse:38.41919\n[3000]\tvalidation_0-rmse:38.37975\n[3100]\tvalidation_0-rmse:38.34970\n[3200]\tvalidation_0-rmse:38.32056\n[3300]\tvalidation_0-rmse:38.28456\n[3400]\tvalidation_0-rmse:38.25250\n[3500]\tvalidation_0-rmse:38.23315\n[3600]\tvalidation_0-rmse:38.19881\n[3700]\tvalidation_0-rmse:38.17198\n[3800]\tvalidation_0-rmse:38.14627\n[3900]\tvalidation_0-rmse:38.12230\n[4000]\tvalidation_0-rmse:38.09453\n[4100]\tvalidation_0-rmse:38.07228\n[4200]\tvalidation_0-rmse:38.04464\n[4300]\tvalidation_0-rmse:38.02942\n[4400]\tvalidation_0-rmse:38.01285\n[4500]\tvalidation_0-rmse:37.99529\n[4600]\tvalidation_0-rmse:37.96554\n[4700]\tvalidation_0-rmse:37.93464\n[4800]\tvalidation_0-rmse:37.91160\n[4900]\tvalidation_0-rmse:37.89456\n[5000]\tvalidation_0-rmse:37.84931\n[5100]\tvalidation_0-rmse:37.82347\n[5200]\tvalidation_0-rmse:37.80177\n[5300]\tvalidation_0-rmse:37.78259\n[5400]\tvalidation_0-rmse:37.75300\n[5500]\tvalidation_0-rmse:37.72406\n[5600]\tvalidation_0-rmse:37.69416\n[5700]\tvalidation_0-rmse:37.65067\n[5800]\tvalidation_0-rmse:37.62557\n[5900]\tvalidation_0-rmse:37.59761\n[6000]\tvalidation_0-rmse:37.56615\n[6100]\tvalidation_0-rmse:37.53846\n[6200]\tvalidation_0-rmse:37.51041\n[6300]\tvalidation_0-rmse:37.49707\n[6400]\tvalidation_0-rmse:37.48505\n[6500]\tvalidation_0-rmse:37.46239\n[6600]\tvalidation_0-rmse:37.44707\n[6700]\tvalidation_0-rmse:37.43931\n[6800]\tvalidation_0-rmse:37.44375\n[6900]\tvalidation_0-rmse:37.44573\n[7000]\tvalidation_0-rmse:37.43661\n[7100]\tvalidation_0-rmse:37.43329\n[7200]\tvalidation_0-rmse:37.43638\n[7300]\tvalidation_0-rmse:37.41753\n[7400]\tvalidation_0-rmse:37.40752\n[7500]\tvalidation_0-rmse:37.39805\n[7600]\tvalidation_0-rmse:37.39073\n[7700]\tvalidation_0-rmse:37.39709\n[7800]\tvalidation_0-rmse:37.39815\n[7900]\tvalidation_0-rmse:37.37633\n[8000]\tvalidation_0-rmse:37.36489\n[8100]\tvalidation_0-rmse:37.35361\n[8200]\tvalidation_0-rmse:37.34336\n[8300]\tvalidation_0-rmse:37.34134\n[8400]\tvalidation_0-rmse:37.33822\n[8500]\tvalidation_0-rmse:37.33669\n[8600]\tvalidation_0-rmse:37.33689\n[8700]\tvalidation_0-rmse:37.33009\n[8800]\tvalidation_0-rmse:37.31816\n[8900]\tvalidation_0-rmse:37.31057\n[9000]\tvalidation_0-rmse:37.30245\n[9100]\tvalidation_0-rmse:37.30767\n[9200]\tvalidation_0-rmse:37.30583\n[9300]\tvalidation_0-rmse:37.30573\n[9400]\tvalidation_0-rmse:37.30139\n[9500]\tvalidation_0-rmse:37.31078\n[9600]\tvalidation_0-rmse:37.31222\n[9700]\tvalidation_0-rmse:37.31495\n[9800]\tvalidation_0-rmse:37.31126\n[9871]\tvalidation_0-rmse:37.31264\nTrain model on 3475 examples\nModel trained in 0:00:05.694056\nFold 4 RMSE: 36.09018829966297\n========== Fold 5 ==========\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006159 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1910\n[LightGBM] [Info] Number of data points in the train set: 3475, number of used features: 195\n[LightGBM] [Info] Start training from score 157.063309\nTraining until validation scores don't improve for 500 rounds\n[100]\tvalid's rmse: 46.2887\n[200]\tvalid's rmse: 42.8784\n[300]\tvalid's rmse: 41.7866\n[400]\tvalid's rmse: 41.3726\n[500]\tvalid's rmse: 41.0776\n[600]\tvalid's rmse: 40.9306\n[700]\tvalid's rmse: 40.8462\n[800]\tvalid's rmse: 40.7456\n[900]\tvalid's rmse: 40.6874\n[1000]\tvalid's rmse: 40.6109\n[1100]\tvalid's rmse: 40.5364\n[1200]\tvalid's rmse: 40.5211\n[1300]\tvalid's rmse: 40.4733\n[1400]\tvalid's rmse: 40.4645\n[1500]\tvalid's rmse: 40.4567\n[1600]\tvalid's rmse: 40.4233\n[1700]\tvalid's rmse: 40.3846\n[1800]\tvalid's rmse: 40.3589\n[1900]\tvalid's rmse: 40.3868\n[2000]\tvalid's rmse: 40.3893\n[2100]\tvalid's rmse: 40.375\n[2200]\tvalid's rmse: 40.3717\n[2300]\tvalid's rmse: 40.3853\nEarly stopping, best iteration is:\n[1809]\tvalid's rmse: 40.3567\n0:\tlearn: 60.6020805\ttest: 60.8146220\tbest: 60.8146220 (0)\ttotal: 37.8ms\tremaining: 6m 17s\n100:\tlearn: 44.7876389\ttest: 47.7821271\tbest: 47.7821271 (100)\ttotal: 3.63s\tremaining: 5m 55s\n200:\tlearn: 38.4413773\ttest: 43.9840904\tbest: 43.9840904 (200)\ttotal: 7.38s\tremaining: 6m\n300:\tlearn: 34.9888618\ttest: 42.4981671\tbest: 42.4981671 (300)\ttotal: 11.2s\tremaining: 6m\n400:\tlearn: 32.6991160\ttest: 41.7931370\tbest: 41.7931370 (400)\ttotal: 15s\tremaining: 5m 58s\n500:\tlearn: 31.1878619\ttest: 41.4408054\tbest: 41.4408054 (500)\ttotal: 18.7s\tremaining: 5m 55s\n600:\tlearn: 29.8130834\ttest: 41.1529627\tbest: 41.1519197 (599)\ttotal: 22.5s\tremaining: 5m 52s\n700:\tlearn: 28.5678955\ttest: 40.9410598\tbest: 40.9410598 (700)\ttotal: 26.4s\tremaining: 5m 49s\n800:\tlearn: 27.5068798\ttest: 40.8145177\tbest: 40.8145177 (800)\ttotal: 30.3s\tremaining: 5m 47s\n900:\tlearn: 26.4914383\ttest: 40.6691942\tbest: 40.6691942 (900)\ttotal: 34.2s\tremaining: 5m 45s\n1000:\tlearn: 25.5765152\ttest: 40.5798557\tbest: 40.5788398 (995)\ttotal: 38.2s\tremaining: 5m 43s\n1100:\tlearn: 24.7858424\ttest: 40.4909331\tbest: 40.4909331 (1100)\ttotal: 42.3s\tremaining: 5m 41s\n1200:\tlearn: 24.0217345\ttest: 40.4066948\tbest: 40.4060410 (1199)\ttotal: 46.2s\tremaining: 5m 38s\n1300:\tlearn: 23.3282575\ttest: 40.3056248\tbest: 40.3056248 (1300)\ttotal: 50.3s\tremaining: 5m 36s\n1400:\tlearn: 22.6154646\ttest: 40.2040256\tbest: 40.2040256 (1400)\ttotal: 54.3s\tremaining: 5m 33s\n1500:\tlearn: 21.9878008\ttest: 40.1390745\tbest: 40.1390745 (1500)\ttotal: 58.3s\tremaining: 5m 30s\n1600:\tlearn: 21.3563536\ttest: 40.0831464\tbest: 40.0815617 (1595)\ttotal: 1m 2s\tremaining: 5m 27s\n1700:\tlearn: 20.7844982\ttest: 40.0428846\tbest: 40.0428846 (1700)\ttotal: 1m 6s\tremaining: 5m 25s\n1800:\tlearn: 20.2367566\ttest: 40.0092052\tbest: 40.0092052 (1800)\ttotal: 1m 10s\tremaining: 5m 22s\n1900:\tlearn: 19.7420993\ttest: 39.9741033\tbest: 39.9741033 (1900)\ttotal: 1m 14s\tremaining: 5m 18s\n2000:\tlearn: 19.2529603\ttest: 39.9408195\tbest: 39.9408195 (2000)\ttotal: 1m 18s\tremaining: 5m 15s\n2100:\tlearn: 18.7771042\ttest: 39.9147452\tbest: 39.9145079 (2091)\ttotal: 1m 22s\tremaining: 5m 12s\n2200:\tlearn: 18.3062973\ttest: 39.8881893\tbest: 39.8852027 (2197)\ttotal: 1m 27s\tremaining: 5m 8s\n2300:\tlearn: 17.8701153\ttest: 39.8558860\tbest: 39.8553454 (2299)\ttotal: 1m 31s\tremaining: 5m 5s\n2400:\tlearn: 17.4196055\ttest: 39.8172192\tbest: 39.8168238 (2398)\ttotal: 1m 35s\tremaining: 5m 1s\n2500:\tlearn: 17.0548776\ttest: 39.8043725\tbest: 39.7980933 (2478)\ttotal: 1m 39s\tremaining: 4m 57s\n2600:\tlearn: 16.6672816\ttest: 39.7962510\tbest: 39.7960354 (2595)\ttotal: 1m 43s\tremaining: 4m 54s\n2700:\tlearn: 16.2809615\ttest: 39.7818844\tbest: 39.7801440 (2693)\ttotal: 1m 47s\tremaining: 4m 50s\n2800:\tlearn: 15.9442100\ttest: 39.7606711\tbest: 39.7603760 (2797)\ttotal: 1m 51s\tremaining: 4m 46s\n2900:\tlearn: 15.6221206\ttest: 39.7549912\tbest: 39.7546523 (2894)\ttotal: 1m 55s\tremaining: 4m 42s\n3000:\tlearn: 15.3253460\ttest: 39.7592081\tbest: 39.7531690 (2930)\ttotal: 1m 59s\tremaining: 4m 39s\n3100:\tlearn: 15.0418358\ttest: 39.7446480\tbest: 39.7446480 (3100)\ttotal: 2m 3s\tremaining: 4m 35s\n3200:\tlearn: 14.7213858\ttest: 39.7307240\tbest: 39.7298655 (3194)\ttotal: 2m 8s\tremaining: 4m 31s\n3300:\tlearn: 14.4490571\ttest: 39.7247248\tbest: 39.7233333 (3240)\ttotal: 2m 12s\tremaining: 4m 28s\n3400:\tlearn: 14.1719063\ttest: 39.7241786\tbest: 39.7233333 (3240)\ttotal: 2m 16s\tremaining: 4m 24s\n3500:\tlearn: 13.8966300\ttest: 39.7230954\tbest: 39.7220905 (3469)\ttotal: 2m 20s\tremaining: 4m 20s\n3600:\tlearn: 13.5918342\ttest: 39.7127573\tbest: 39.7116190 (3599)\ttotal: 2m 24s\tremaining: 4m 16s\n3700:\tlearn: 13.3440176\ttest: 39.6939004\tbest: 39.6939004 (3700)\ttotal: 2m 28s\tremaining: 4m 13s\n3800:\tlearn: 13.0936435\ttest: 39.6823896\tbest: 39.6823896 (3800)\ttotal: 2m 32s\tremaining: 4m 9s\n3900:\tlearn: 12.8644992\ttest: 39.6746895\tbest: 39.6746895 (3900)\ttotal: 2m 37s\tremaining: 4m 5s\n4000:\tlearn: 12.6203249\ttest: 39.6744750\tbest: 39.6725264 (3941)\ttotal: 2m 41s\tremaining: 4m 1s\n4100:\tlearn: 12.4133647\ttest: 39.6622922\tbest: 39.6611813 (4096)\ttotal: 2m 45s\tremaining: 3m 58s\n4200:\tlearn: 12.2029088\ttest: 39.6590524\tbest: 39.6563277 (4184)\ttotal: 2m 49s\tremaining: 3m 54s\n4300:\tlearn: 12.0059448\ttest: 39.6526536\tbest: 39.6505469 (4275)\ttotal: 2m 53s\tremaining: 3m 50s\n4400:\tlearn: 11.7885460\ttest: 39.6552348\tbest: 39.6505469 (4275)\ttotal: 2m 57s\tremaining: 3m 46s\n4500:\tlearn: 11.6014619\ttest: 39.6542092\tbest: 39.6505469 (4275)\ttotal: 3m 2s\tremaining: 3m 42s\n4600:\tlearn: 11.3989429\ttest: 39.6461028\tbest: 39.6456500 (4593)\ttotal: 3m 6s\tremaining: 3m 38s\n4700:\tlearn: 11.2129675\ttest: 39.6494034\tbest: 39.6445683 (4626)\ttotal: 3m 10s\tremaining: 3m 34s\n4800:\tlearn: 11.0318461\ttest: 39.6427409\tbest: 39.6426023 (4793)\ttotal: 3m 14s\tremaining: 3m 30s\n4900:\tlearn: 10.8342096\ttest: 39.6436776\tbest: 39.6405618 (4803)\ttotal: 3m 18s\tremaining: 3m 26s\n5000:\tlearn: 10.6779123\ttest: 39.6457981\tbest: 39.6405618 (4803)\ttotal: 3m 22s\tremaining: 3m 22s\n5100:\tlearn: 10.5086008\ttest: 39.6446829\tbest: 39.6405618 (4803)\ttotal: 3m 27s\tremaining: 3m 18s\n5200:\tlearn: 10.3306552\ttest: 39.6453277\tbest: 39.6405618 (4803)\ttotal: 3m 31s\tremaining: 3m 14s\n5300:\tlearn: 10.1377380\ttest: 39.6412938\tbest: 39.6404302 (5271)\ttotal: 3m 35s\tremaining: 3m 10s\n5400:\tlearn: 9.9834261\ttest: 39.6363184\tbest: 39.6363184 (5400)\ttotal: 3m 39s\tremaining: 3m 7s\n5500:\tlearn: 9.8277770\ttest: 39.6387807\tbest: 39.6363184 (5400)\ttotal: 3m 43s\tremaining: 3m 3s\n5600:\tlearn: 9.6584606\ttest: 39.6362685\tbest: 39.6358662 (5592)\ttotal: 3m 47s\tremaining: 2m 59s\n5700:\tlearn: 9.5231861\ttest: 39.6357733\tbest: 39.6343127 (5618)\ttotal: 3m 52s\tremaining: 2m 54s\n5800:\tlearn: 9.3695144\ttest: 39.6288895\tbest: 39.6288895 (5800)\ttotal: 3m 56s\tremaining: 2m 50s\n5900:\tlearn: 9.2382029\ttest: 39.6238189\tbest: 39.6238189 (5900)\ttotal: 4m\tremaining: 2m 46s\n6000:\tlearn: 9.0849740\ttest: 39.6207696\tbest: 39.6206550 (5933)\ttotal: 4m 4s\tremaining: 2m 42s\n6100:\tlearn: 8.9605752\ttest: 39.6231118\tbest: 39.6196165 (6022)\ttotal: 4m 8s\tremaining: 2m 38s\n6200:\tlearn: 8.8241690\ttest: 39.6218785\tbest: 39.6196165 (6022)\ttotal: 4m 12s\tremaining: 2m 34s\n6300:\tlearn: 8.7003834\ttest: 39.6222985\tbest: 39.6196165 (6022)\ttotal: 4m 17s\tremaining: 2m 30s\n6400:\tlearn: 8.5735723\ttest: 39.6244888\tbest: 39.6196165 (6022)\ttotal: 4m 21s\tremaining: 2m 26s\n6500:\tlearn: 8.4597126\ttest: 39.6250689\tbest: 39.6196165 (6022)\ttotal: 4m 25s\tremaining: 2m 22s\nStopped by overfitting detector  (500 iterations wait)\n\nbestTest = 39.61961651\nbestIteration = 6022\n\nShrink model to first 6023 iterations.\n[0]\tvalidation_0-rmse:60.80225\n[100]\tvalidation_0-rmse:48.19120\n[200]\tvalidation_0-rmse:44.82936\n[300]\tvalidation_0-rmse:43.40490\n[400]\tvalidation_0-rmse:42.74744\n[500]\tvalidation_0-rmse:42.41459\n[600]\tvalidation_0-rmse:42.21728\n[700]\tvalidation_0-rmse:42.11218\n[800]\tvalidation_0-rmse:42.08901\n[900]\tvalidation_0-rmse:42.03635\n[1000]\tvalidation_0-rmse:41.97617\n[1100]\tvalidation_0-rmse:41.95642\n[1200]\tvalidation_0-rmse:41.93374\n[1300]\tvalidation_0-rmse:41.89462\n[1400]\tvalidation_0-rmse:41.87301\n[1500]\tvalidation_0-rmse:41.84167\n[1600]\tvalidation_0-rmse:41.82574\n[1700]\tvalidation_0-rmse:41.79693\n[1800]\tvalidation_0-rmse:41.75140\n[1900]\tvalidation_0-rmse:41.70383\n[2000]\tvalidation_0-rmse:41.65924\n[2100]\tvalidation_0-rmse:41.61516\n[2200]\tvalidation_0-rmse:41.59281\n[2300]\tvalidation_0-rmse:41.55270\n[2400]\tvalidation_0-rmse:41.51079\n[2500]\tvalidation_0-rmse:41.48190\n[2600]\tvalidation_0-rmse:41.46074\n[2700]\tvalidation_0-rmse:41.43582\n[2800]\tvalidation_0-rmse:41.42350\n[2900]\tvalidation_0-rmse:41.42211\n[3000]\tvalidation_0-rmse:41.43085\n[3100]\tvalidation_0-rmse:41.43078\n[3200]\tvalidation_0-rmse:41.41491\n[3300]\tvalidation_0-rmse:41.41324\n[3400]\tvalidation_0-rmse:41.40218\n[3500]\tvalidation_0-rmse:41.39616\n[3600]\tvalidation_0-rmse:41.38490\n[3700]\tvalidation_0-rmse:41.38598\n[3800]\tvalidation_0-rmse:41.39252\n[3900]\tvalidation_0-rmse:41.39685\n[4000]\tvalidation_0-rmse:41.40507\n[4100]\tvalidation_0-rmse:41.40846\n[4110]\tvalidation_0-rmse:41.40576\nTrain model on 3475 examples\nModel trained in 0:00:10.699503\nFold 5 RMSE: 39.460387108267945\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(merged_df), 1):\n",
    "    print(f\"========== Fold {fold} ==========\")\n",
    "    train_X, val_X = merged_df.iloc[train_index], merged_df.iloc[val_index]\n",
    "    train_y, val_y = Y.iloc[train_index], Y.iloc[val_index]\n",
    "\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "\n",
    "    # Scikit-learn\n",
    "    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    encoded_train_X = encoder.fit_transform(train_X.select_dtypes(include=['category']))\n",
    "    encoded_val_X = encoder.transform(val_X.select_dtypes(include=['category']))\n",
    "\n",
    "    # Combine encoded features with the rest of the dataset\n",
    "    train_X_encoded = np.hstack([train_X.select_dtypes(exclude=['category']).values, encoded_train_X])\n",
    "    val_X_encoded = np.hstack([val_X.select_dtypes(exclude=['category']).values, encoded_val_X])\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    train_X_encoded = imputer.fit_transform(train_X_encoded)\n",
    "    val_X_encoded = imputer.transform(val_X_encoded)\n",
    "    \n",
    "    # Sklearn Gradient Boosting\n",
    "    model5 = GradientBoostingRegressor(\n",
    "        n_estimators=10000, learning_rate=0.01, max_depth=3, random_state=42\n",
    "    )\n",
    "    model5.fit(train_X_encoded, train_y)\n",
    "    pred5 = model5.predict(val_X_encoded)\n",
    "\n",
    "\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "\n",
    "    # LightGBM\n",
    "    train_data_lgb = lgb.Dataset(train_X, label=train_y, categorical_feature='auto')\n",
    "    val_data_lgb = lgb.Dataset(val_X, label=val_y, categorical_feature='auto')\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 10000,\n",
    "        'random_seed': 42\n",
    "    }\n",
    "    model1 = lgb.train(\n",
    "        params,\n",
    "        train_data_lgb,\n",
    "        valid_sets=[val_data_lgb],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=500, verbose=True),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "    pred1 = model1.predict(val_X, num_iteration=model1.best_iteration)\n",
    "\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "\n",
    "    # CatBoost\n",
    "    model2 = CatBoostRegressor(\n",
    "        iterations=10000, learning_rate=0.01, depth=10, loss_function='RMSE',\n",
    "        cat_features=train_X.select_dtypes(include=['category']).columns.to_list(),\n",
    "        verbose=100, early_stopping_rounds=500\n",
    "    )\n",
    "    model2.fit(train_X, train_y, eval_set=(val_X, val_y))\n",
    "    pred2 = model2.predict(val_X)\n",
    "\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "\n",
    "    # XGBoost\n",
    "    model3 = XGBRegressor(\n",
    "        n_estimators=10000, learning_rate=0.01,\n",
    "        max_depth=3, random_state=42,\n",
    "        enable_categorical=True,\n",
    "        eval_metric='rmse', early_stopping_rounds=500, verbosity=1\n",
    "    )\n",
    "    model3.fit(train_X, train_y, eval_set=[(val_X, val_y)], verbose=100)\n",
    "    pred3 = model3.predict(val_X)\n",
    "\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "\n",
    "    # YDF \n",
    "    train_data_combined = train_X.copy()\n",
    "    train_data_combined['composite_score'] = train_y\n",
    "    # train_ds = ydf.Dataset.from_pandas(train_data_combined, label='composite_score')\n",
    "    \n",
    "    model4 = (\n",
    "        ydf.GradientBoostedTreesLearner(\n",
    "            label='composite_score', \n",
    "            task=ydf.Task.REGRESSION,\n",
    "            **ydf_params\n",
    "        )\n",
    "        .train(train_data_combined)\n",
    "    )\n",
    "    pred4 = model4.predict(val_X)  # predicts directly from val_X DataFrame\n",
    "\n",
    "\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "\n",
    "    # Optimize weights for all five models\n",
    "    def loss_function(weights):\n",
    "        w1, w2, w3, w4, w5 = weights\n",
    "        combined_predictions = (w1*pred1 + w2*pred2 + w3*pred3 + w4*pred4 + w5*pred5)\n",
    "        mse = np.mean((combined_predictions - val_y) ** 2)\n",
    "        return mse\n",
    "\n",
    "    initial_weights = np.array([1/5]*5)\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: w.sum() - 1}\n",
    "    bounds = [(0,1)]*5\n",
    "\n",
    "    result = minimize(loss_function, initial_weights, constraints=constraints, bounds=bounds)\n",
    "    optimized_weights = result.x\n",
    "\n",
    "    final_predictions = (optimized_weights[0]*pred1 +\n",
    "                         optimized_weights[1]*pred2 +\n",
    "                         optimized_weights[2]*pred3 +\n",
    "                         optimized_weights[3]*pred4 +\n",
    "                         optimized_weights[4]*pred5)\n",
    "\n",
    "    fold_rmse = np.sqrt(mean_squared_error(val_y, final_predictions))\n",
    "    print(f\"Fold {fold} RMSE: {fold_rmse}\")\n",
    "    fold_results.append(fold_rmse)\n",
    "    optimized_weights_list.append(optimized_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb9b04bd-5dd9-4f30-85ac-bb3a5829eb65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# post epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1872f51-6aff-4389-bf2a-92931171c6b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE across folds: 37.006780187843816\nOptimized weights per fold: [array([6.93830566e-02, 2.83848311e-01, 1.17890399e-01, 5.28878234e-01,\n       1.80127708e-17]), array([0.326815  , 0.4468834 , 0.04331949, 0.09240241, 0.09058018]), array([1.68981217e-10, 6.10708456e-01, 2.23672114e-01, 1.65619430e-01,\n       2.48355744e-10]), array([5.41519188e-01, 2.00986976e-01, 7.81143646e-02, 1.79379472e-01,\n       7.64363522e-11]), array([7.20910897e-02, 6.39050236e-01, 2.65575661e-16, 2.18849886e-01,\n       7.00087885e-02])]\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005088 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2030\n[LightGBM] [Info] Number of data points in the train set: 4343, number of used features: 195\n[LightGBM] [Info] Start training from score 157.016809\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 4343 examples\nModel trained in 0:00:04.554793\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "\u001B[0;32m~/.ipykernel/2701/command-4042265090800783-2968310636\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m     54\u001B[0m \u001B[0;31m# Scikit-learn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     55\u001B[0m final_model5 = GradientBoostingRegressor(\n",
       "\u001B[1;32m     56\u001B[0m     \u001B[0mn_estimators\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_depth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m42\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     57\u001B[0m )\n",
       "\u001B[0;32m---> 58\u001B[0;31m \u001B[0mfinal_model5\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmerged_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     61\u001B[0m \u001B[0;31m# Generate predictions on the test dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     31\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0moriginal_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     32\u001B[0m             \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     33\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     34\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0msess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_log\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0m_is_allowlisted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallowlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 35\u001B[0;31m                         func_call_logger.log(\n",
       "\u001B[0m\u001B[1;32m     36\u001B[0m                             \u001B[0mmodel_class\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_get_fully_qualified_class_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     37\u001B[0m                             \u001B[0mmodel_function\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     38\u001B[0m                             \u001B[0mworkload_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_map_func_to_ml_workload_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunction_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1147\u001B[0m                 skip_parameter_validation=(\n",
       "\u001B[1;32m   1148\u001B[0m                     \u001B[0mprefer_skip_nested_validation\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mglobal_skip_validation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1149\u001B[0m                 )\n",
       "\u001B[1;32m   1150\u001B[0m             ):\n",
       "\u001B[0;32m-> 1151\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfit_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\n",
       "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, sample_weight, monitor)\u001B[0m\n",
       "\u001B[1;32m    412\u001B[0m         \u001B[0;31m# Check input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    413\u001B[0m         \u001B[0;31m# Since check_array converts both X and y to the same dtype, but the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    414\u001B[0m         \u001B[0;31m# trees use different types for X and y, checking them separately.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    415\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 416\u001B[0;31m         X, y = self._validate_data(\n",
       "\u001B[0m\u001B[1;32m    417\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"csr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"csc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"coo\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    418\u001B[0m         )\n",
       "\u001B[1;32m    419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n",
       "\u001B[1;32m    617\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;34m\"estimator\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcheck_y_params\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    618\u001B[0m                     \u001B[0mcheck_y_params\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mdefault_check_params\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    619\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"y\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    620\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 621\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    622\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    623\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    624\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ensure_2d\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n",
       "\u001B[1;32m   1143\u001B[0m         raise ValueError(\n",
       "\u001B[1;32m   1144\u001B[0m             \u001B[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1145\u001B[0m         )\n",
       "\u001B[1;32m   1146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1147\u001B[0;31m     X = check_array(\n",
       "\u001B[0m\u001B[1;32m   1148\u001B[0m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1149\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1150\u001B[0m         \u001B[0maccept_large_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n",
       "\u001B[1;32m    914\u001B[0m                         )\n",
       "\u001B[1;32m    915\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    916\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    917\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 918\u001B[0;31m             \u001B[0;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    919\u001B[0m                 raise ValueError(\n",
       "\u001B[1;32m    920\u001B[0m                     \u001B[0;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    921\u001B[0m                 ) from complex_warning\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(array, dtype, order, copy, xp)\u001B[0m\n",
       "\u001B[1;32m    376\u001B[0m         \u001B[0;31m# Use NumPy API to support order\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    377\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    378\u001B[0m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    379\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 380\u001B[0;31m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    381\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    382\u001B[0m         \u001B[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    383\u001B[0m         \u001B[0;31m# container that is consistent with the input's namespace.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, dtype)\u001B[0m\n",
       "\u001B[1;32m   2069\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 2070\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'Missing'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "could not convert string to float: 'Missing'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: could not convert string to float: 'Missing'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "\u001B[0;32m~/.ipykernel/2701/command-4042265090800783-2968310636\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;31m# Scikit-learn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m final_model5 = GradientBoostingRegressor(\n\u001B[1;32m     56\u001B[0m     \u001B[0mn_estimators\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_depth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m42\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m )\n\u001B[0;32m---> 58\u001B[0;31m \u001B[0mfinal_model5\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmerged_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[0;31m# Generate predictions on the test dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
        "\u001B[0;32m/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0moriginal_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m             \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0msess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_log\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0m_is_allowlisted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallowlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m                         func_call_logger.log(\n\u001B[0m\u001B[1;32m     36\u001B[0m                             \u001B[0mmodel_class\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_get_fully_qualified_class_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m                             \u001B[0mmodel_function\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m                             \u001B[0mworkload_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_map_func_to_ml_workload_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunction_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
        "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1147\u001B[0m                 skip_parameter_validation=(\n\u001B[1;32m   1148\u001B[0m                     \u001B[0mprefer_skip_nested_validation\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mglobal_skip_validation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m                 )\n\u001B[1;32m   1150\u001B[0m             ):\n\u001B[0;32m-> 1151\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfit_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
        "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[1;32m    412\u001B[0m         \u001B[0;31m# Check input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    413\u001B[0m         \u001B[0;31m# Since check_array converts both X and y to the same dtype, but the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    414\u001B[0m         \u001B[0;31m# trees use different types for X and y, checking them separately.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    415\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 416\u001B[0;31m         X, y = self._validate_data(\n\u001B[0m\u001B[1;32m    417\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"csr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"csc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"coo\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    418\u001B[0m         )\n\u001B[1;32m    419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
        "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    617\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;34m\"estimator\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcheck_y_params\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    618\u001B[0m                     \u001B[0mcheck_y_params\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mdefault_check_params\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    619\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"y\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    620\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 621\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    622\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    623\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    624\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ensure_2d\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
        "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1143\u001B[0m         raise ValueError(\n\u001B[1;32m   1144\u001B[0m             \u001B[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1145\u001B[0m         )\n\u001B[1;32m   1146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m     X = check_array(\n\u001B[0m\u001B[1;32m   1148\u001B[0m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1150\u001B[0m         \u001B[0maccept_large_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
        "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    914\u001B[0m                         )\n\u001B[1;32m    915\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 918\u001B[0;31m             \u001B[0;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    919\u001B[0m                 raise ValueError(\n\u001B[1;32m    920\u001B[0m                     \u001B[0;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    921\u001B[0m                 ) from complex_warning\n",
        "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[1;32m    376\u001B[0m         \u001B[0;31m# Use NumPy API to support order\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    377\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    378\u001B[0m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    379\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 380\u001B[0;31m             \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    381\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    382\u001B[0m         \u001B[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m         \u001B[0;31m# container that is consistent with the input's namespace.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
        "\u001B[0;32m/databricks/python/lib/python3.11/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   2069\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2070\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'Missing'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# post epoch results\n",
    "\n",
    "# Display average results\n",
    "final_cv_rmse = np.mean(fold_results)\n",
    "print(f\"Average RMSE across folds: {final_cv_rmse}\")\n",
    "print(f\"Optimized weights per fold: {optimized_weights_list}\")\n",
    "\n",
    "# Calculate the average weights from cross-validation\n",
    "average_weights = np.mean(optimized_weights_list, axis=0)\n",
    "\n",
    "# LightGBM\n",
    "final_train_data_lgb = lgb.Dataset(merged_df, label=Y, categorical_feature='auto')\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 10000,\n",
    "    'random_seed': 42\n",
    "}\n",
    "final_model1 = lgb.train(\n",
    "    params,\n",
    "    final_train_data_lgb\n",
    ")\n",
    "\n",
    "# CatBoost\n",
    "final_model2 = CatBoostRegressor(\n",
    "    iterations=10000, learning_rate=0.01, depth=10, loss_function='RMSE',\n",
    "    cat_features=merged_df.select_dtypes(include=['category']).columns.to_list(),\n",
    "    verbose=False\n",
    ")\n",
    "final_model2.fit(merged_df, Y, verbose=False)\n",
    "\n",
    "# XGBoost \n",
    "final_model3 = XGBRegressor(\n",
    "    n_estimators=10000, learning_rate=0.01,\n",
    "    max_depth=3, random_state=42,\n",
    "    enable_categorical=True,\n",
    "    eval_metric='rmse', verbosity=0\n",
    ")\n",
    "final_model3.fit(merged_df, Y, verbose=False)\n",
    "\n",
    "# Yggdrusil \n",
    "train_data_full_combined = merged_df.copy()\n",
    "train_data_full_combined['composite_score'] = Y\n",
    "final_model4 = (\n",
    "    ydf.GradientBoostedTreesLearner(\n",
    "        label='composite_score', \n",
    "        task=ydf.Task.REGRESSION,\n",
    "        **ydf_params\n",
    "    )\n",
    "    .train(train_data_full_combined)\n",
    ")\n",
    "\n",
    "# Scikit-learn \n",
    "final_model5 = GradientBoostingRegressor(\n",
    "    n_estimators=10000, learning_rate=0.01, max_depth=3, random_state=42\n",
    ")\n",
    "final_model5.fit(merged_df, Y)\n",
    "\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "test_pred1 = final_model1.predict(merged_test)\n",
    "test_pred2 = final_model2.predict(merged_test)\n",
    "test_pred3 = final_model3.predict(merged_test)\n",
    "test_pred4 = final_model4.predict(merged_test)\n",
    "test_pred5 = final_model5.predict(merged_test)\n",
    "\n",
    "final_test_predictions = (\n",
    "    average_weights[0] * test_pred1 +\n",
    "    average_weights[1] * test_pred2 +\n",
    "    average_weights[2] * test_pred3 +\n",
    "    average_weights[3] * test_pred4 +\n",
    "    average_weights[4] * test_pred5\n",
    ")\n",
    "\n",
    "final_test_predictions = np.round(final_test_predictions).astype(int)\n",
    "\n",
    "print(\"Final blended predictions for the test dataset:\")\n",
    "print(final_test_predictions)\n",
    "\n",
    "ss['composite_score']=final_test_predictions\n",
    "ss.to_csv('LGBM_CatBoost_XGBoost_YDF_SklearnGB_FINAL.csv', index=False)\n",
    "\n",
    "print(f\"FINAL ENSEMBLE RMSE (CV average): {final_cv_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a705c181-f964-4715-b82e-3ac9ccbd91ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## clean data for Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7fa446b-5643-438d-ab78-ac5b5a7f9a5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/2701/command-4042265090800827-3631540630:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  merged_test.replace('Missing', np.nan, inplace=True)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NaN count after imputation: 0\nTest NaN count after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Missing' with NaN\n",
    "merged_df.replace('Missing', np.nan, inplace=True)\n",
    "merged_test.replace('Missing', np.nan, inplace=True)\n",
    "\n",
    "# Convert all columns to numeric, coerce non-numeric to NaN\n",
    "merged_df = merged_df.apply(pd.to_numeric, errors='coerce')\n",
    "merged_test = merged_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop any columns in both train/test that are entirely NaN\n",
    "all_nan_cols = merged_df.columns[merged_df.isnull().all()]\n",
    "merged_df.drop(all_nan_cols, axis=1, inplace=True)\n",
    "merged_test.drop(all_nan_cols, axis=1, inplace=True)\n",
    "\n",
    "# Impute missing values using mean for each column\n",
    "merged_df.fillna(merged_df.mean(), inplace=True)\n",
    "merged_test.fillna(merged_test.mean(), inplace=True)\n",
    "\n",
    "# Double-check no NaNs remain\n",
    "print(\"Train NaN count after imputation:\", merged_df.isnull().sum().sum())\n",
    "print(\"Test NaN count after imputation:\", merged_test.isnull().sum().sum())\n",
    "\n",
    "# Now merged_df and merged_test should have no NaNs and be purely numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1129e574-c746-4c77-b4b8-d172f1836dd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values by replacing 'Missing' with NaN and then imputing or dropping\n",
    "merged_df.replace('Missing', np.nan, inplace=True)\n",
    "\n",
    "# Option 2: Impute missing values (e.g., with the mean of the column)\n",
    "merged_df.fillna(merged_df.mean(), inplace=True)\n",
    "\n",
    "# post epoch results\n",
    "\n",
    "# Display average results\n",
    "final_cv_rmse = np.mean(fold_results)\n",
    "print(f\"Average RMSE across folds: {final_cv_rmse}\")\n",
    "print(f\"Optimized weights per fold: {optimized_weights_list}\")\n",
    "\n",
    "# Calculate the average weights from cross-validation\n",
    "average_weights = np.mean(optimized_weights_list, axis=0)\n",
    "\n",
    "\n",
    "# Scikit-learn \n",
    "final_model5 = GradientBoostingRegressor(\n",
    "    n_estimators=10000, learning_rate=0.01, max_depth=3, random_state=42\n",
    ")\n",
    "final_model5.fit(merged_df, Y)\n",
    "\n",
    "# LightGBM\n",
    "final_train_data_lgb = lgb.Dataset(merged_df, label=Y, categorical_feature='auto')\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 10000,\n",
    "    'random_seed': 42\n",
    "}\n",
    "final_model1 = lgb.train(\n",
    "    params,\n",
    "    final_train_data_lgb\n",
    ")\n",
    "\n",
    "# CatBoost\n",
    "final_model2 = CatBoostRegressor(\n",
    "    iterations=10000, learning_rate=0.01, depth=10, loss_function='RMSE',\n",
    "    cat_features=merged_df.select_dtypes(include=['category']).columns.to_list(),\n",
    "    verbose=False\n",
    ")\n",
    "final_model2.fit(merged_df, Y, verbose=False)\n",
    "\n",
    "# XGBoost \n",
    "final_model3 = XGBRegressor(\n",
    "    n_estimators=10000, learning_rate=0.01,\n",
    "    max_depth=3, random_state=42,\n",
    "    enable_categorical=True,\n",
    "    eval_metric='rmse', verbosity=0\n",
    ")\n",
    "final_model3.fit(merged_df, Y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f298b250-9025-442d-809d-77c026f9a5e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## ydf onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "914aceb8-6623-4ec5-8b19-ab8b222d557d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 4343 examples\nModel trained in 0:00:09.632628\nFinal blended predictions for the test dataset:\n[188 201 207 ... 185 166 149]\nFINAL ENSEMBLE RMSE (CV average): 37.006780187843816\n"
     ]
    }
   ],
   "source": [
    "# Yggdrusil \n",
    "train_data_full_combined = merged_df.copy()\n",
    "train_data_full_combined['composite_score'] = Y\n",
    "final_model4 = (\n",
    "    ydf.GradientBoostedTreesLearner(\n",
    "        label='composite_score', \n",
    "        task=ydf.Task.REGRESSION,\n",
    "        **ydf_params\n",
    "    )\n",
    "    .train(train_data_full_combined)\n",
    ")\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "test_pred1 = final_model1.predict(merged_test)\n",
    "test_pred2 = final_model2.predict(merged_test)\n",
    "test_pred3 = final_model3.predict(merged_test)\n",
    "test_pred4 = final_model4.predict(merged_test)\n",
    "test_pred5 = final_model5.predict(merged_test)\n",
    "\n",
    "final_test_predictions = (\n",
    "    average_weights[0] * test_pred1 +\n",
    "    average_weights[1] * test_pred2 +\n",
    "    average_weights[2] * test_pred3 +\n",
    "    average_weights[3] * test_pred4 +\n",
    "    average_weights[4] * test_pred5\n",
    ")\n",
    "\n",
    "final_test_predictions = np.round(final_test_predictions).astype(int)\n",
    "\n",
    "print(\"Final blended predictions for the test dataset:\")\n",
    "print(final_test_predictions)\n",
    "\n",
    "ss['composite_score'] = final_test_predictions\n",
    "ss.to_csv('LGBM_CatBoost_XGBoost_YDF_SklearnGB_FINAL.csv', index=False)\n",
    "\n",
    "print(f\"FINAL ENSEMBLE RMSE (CV average): {final_cv_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d5484d9-11ef-4c57-b0d2-2fa562a46f56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "__FINAL 1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}